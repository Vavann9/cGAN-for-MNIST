{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n"
      ],
      "metadata": {
        "id": "VcoMCVmewni1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparamètres\n",
        "latent_dim = 100  # Dimension du bruit aléatoire\n",
        "num_classes = 10  # Nombre de classes dans MNIST (0-9)\n",
        "img_size = 28  # Taille des images\n",
        "channels = 1  # Canal (1 pour grayscale)\n",
        "batch_size = 64\n",
        "lr = 0.0002  # Taux d'apprentissage\n",
        "epochs = 50\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "wzHOG9Bkwvd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset MNIST\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])  # Normalisation entre -1 et 1\n",
        "])\n",
        "mnist = datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
        "dataloader = DataLoader(mnist, batch_size=batch_size, shuffle=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lX_2Ftbw0d-",
        "outputId": "882720c5-b12e-441c-c2ba-170532b800fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 16.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 476kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.85MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.09MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Générateur\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim, num_classes, img_size, channels):\n",
        "        super(Generator, self).__init__()\n",
        "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
        "        self.init_size = img_size // 4\n",
        "        self.l1 = nn.Sequential(nn.Linear(latent_dim + num_classes, 128 * self.init_size ** 2))\n",
        "\n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, channels, 3, stride=1, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, noise, labels):\n",
        "        gen_input = torch.cat((noise, self.label_emb(labels)), -1)\n",
        "        out = self.l1(gen_input)\n",
        "        out = out.view(out.size(0), 128, self.init_size, self.init_size)\n",
        "        img = self.conv_blocks(out)\n",
        "        return img\n",
        "\n",
        "\n",
        "# Discriminateur\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, num_classes, img_size, channels):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(num_classes + int(channels * img_size ** 2), 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img, labels):\n",
        "        d_in = torch.cat((img.view(img.size(0), -1), self.label_emb(labels)), -1)\n",
        "        validity = self.model(d_in)\n",
        "        return validity\n"
      ],
      "metadata": {
        "id": "gPkjp1qjw5ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Générateur : génère des images à partir d'un vecteur aléatoire (latent) et d'une classe donnée.\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim, num_classes, img_size, channels):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        # Embedding des labels (vecteur dense associé à chaque classe)\n",
        "        self.label_emb = nn.Embedding(num_classes, num_classes)  # Taille num_classes pour un one-hot-like embedding\n",
        "\n",
        "        # Taille initiale après le premier reshape (réduction de la taille spatiale)\n",
        "        self.init_size = img_size // 4\n",
        "\n",
        "        # Couche entièrement connectée pour projeter l'entrée (bruit + labels) en un tenseur spatial.\n",
        "        self.l1 = nn.Sequential(\n",
        "            nn.Linear(latent_dim + num_classes, 128 * self.init_size ** 2)  # Projection dans un espace de caractéristiques initiales\n",
        "        )\n",
        "\n",
        "        # Blocs de convolutions pour augmenter la taille spatiale et affiner l'image\n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            nn.BatchNorm2d(128),  # Normalisation des canaux pour stabiliser l'apprentissage\n",
        "            nn.Upsample(scale_factor=2),  # Agrandissement de la taille spatiale (doublement)\n",
        "            nn.Conv2d(128, 128, 3, stride=1, padding=1),  # Convolution pour affiner les motifs\n",
        "            nn.BatchNorm2d(128, 0.8),  # Nouvelle normalisation des canaux\n",
        "            nn.LeakyReLU(0.2, inplace=True),  # Activation non-linéaire pour ajouter de la complexité\n",
        "            nn.Upsample(scale_factor=2),  # Deuxième agrandissement spatial\n",
        "            nn.Conv2d(128, channels, 3, stride=1, padding=1),  # Convolution finale pour générer l'image finale\n",
        "            nn.Tanh()  # Activation Tanh pour ramener les valeurs des pixels entre -1 et 1\n",
        "        )\n",
        "\n",
        "    def forward(self, noise, labels):\n",
        "        # Concatenation du bruit et des embeddings de labels\n",
        "        gen_input = torch.cat((noise, self.label_emb(labels)), -1)\n",
        "\n",
        "        # Projection linéaire et mise en forme pour convolution\n",
        "        out = self.l1(gen_input)\n",
        "        out = out.view(out.size(0), 128, self.init_size, self.init_size)  # Reshape pour correspondre à une entrée convolutive\n",
        "\n",
        "        # Passage dans les blocs convolutifs pour générer l'image\n",
        "        img = self.conv_blocks(out)\n",
        "        return img\n",
        "\n",
        "\n",
        "# Discriminateur : classe le contenu généré comme réel ou faux (GAN classique)\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, num_classes, img_size, channels):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        # Embedding des labels pour les concaténer à l'image\n",
        "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
        "\n",
        "        # Modèle séquentiel pour classifier l'entrée image\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(num_classes + int(channels * img_size ** 2), 512),  # Combinaison image + label dans un espace latent\n",
        "            nn.LeakyReLU(0.2, inplace=True),  # Activation pour capturer des motifs complexes\n",
        "            nn.Linear(512, 512),  # Projection dans un espace réduit\n",
        "            nn.Dropout(0.4),  # Régularisation pour éviter le surapprentissage\n",
        "            nn.LeakyReLU(0.2, inplace=True),  # Activation supplémentaire\n",
        "            nn.Linear(512, 1),  # Sortie unique pour la validité\n",
        "            nn.Sigmoid()  # Probabilité de validité (entre 0 et 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, img, labels):\n",
        "        # Mise à plat de l'image et concaténation avec les embeddings des labels\n",
        "        d_in = torch.cat((img.view(img.size(0), -1), self.label_emb(labels)), -1)\n",
        "\n",
        "        # Passage dans le discriminateur\n",
        "        validity = self.model(d_in)\n",
        "        return validity\n"
      ],
      "metadata": {
        "id": "y_H5-H-3gB7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialisation des modèles\n",
        "generator = Generator(latent_dim, num_classes, img_size, channels).to(device)\n",
        "discriminator = Discriminator(num_classes, img_size, channels).to(device)\n",
        "\n",
        "# Optimiseurs\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "# Fonction de perte\n",
        "adversarial_loss = nn.BCELoss()\n"
      ],
      "metadata": {
        "id": "_QDxPagtw9Wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(50):\n",
        "    for i, (imgs, labels) in enumerate(dataloader):\n",
        "        batch_size = imgs.size(0)\n",
        "\n",
        "        # Réalités et faux labels\n",
        "        valid = torch.ones(batch_size, 1, device=device)\n",
        "        fake = torch.zeros(batch_size, 1, device=device)\n",
        "\n",
        "        # Préparer les données\n",
        "        real_imgs = imgs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # 1. Entraîner le Générateur\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Bruit aléatoire et étiquettes aléatoires\n",
        "        z = torch.randn(batch_size, latent_dim, device=device)\n",
        "        gen_labels = torch.randint(0, num_classes, (batch_size,), device=device)\n",
        "\n",
        "        # Générer des images\n",
        "        gen_imgs = generator(z, gen_labels)\n",
        "\n",
        "        # Calculer la perte du générateur\n",
        "        g_loss = adversarial_loss(discriminator(gen_imgs, gen_labels), valid)\n",
        "\n",
        "        # Backpropagation\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # 2. Entraîner le Discriminateur\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Perte pour les vraies images\n",
        "        real_loss = adversarial_loss(discriminator(real_imgs, labels), valid)\n",
        "\n",
        "        # Perte pour les fausses images\n",
        "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach(), gen_labels), fake)\n",
        "\n",
        "        # Perte totale du Discriminateur\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "        # Backpropagation\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # Affichage des logs\n",
        "        if i % 100 == 0:\n",
        "            print(f\"[Epoch {epoch}/{epochs}] [Batch {i}/{len(dataloader)}] [D loss: {d_loss.item()}] [G loss: {g_loss.item()}]\")\n"
      ],
      "metadata": {
        "id": "Da5KfNtFw_kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def generate_and_save_images(generator, num_images=10):\n",
        "    z = torch.randn(num_images, latent_dim, device=device)\n",
        "    labels = torch.arange(num_images, device=device)\n",
        "    gen_imgs = generator(z, labels).detach().cpu()\n",
        "    fig, axs = plt.subplots(1, num_images, figsize=(15, 15))\n",
        "    for i, img in enumerate(gen_imgs):\n",
        "        axs[i].imshow(img.squeeze(), cmap='gray')\n",
        "        axs[i].axis('off')\n",
        "        axs[i].set_title(f\"Label: {labels[i].item()}\")\n",
        "    plt.show()\n",
        "\n",
        "# Générer des exemples\n",
        "generate_and_save_images(generator)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "id": "ZhYdXdalxFXm",
        "outputId": "ddf9ed7c-0e69-4cc8-d182-f4614979021f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1500 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Hyperparamètres\n",
        "latent_dim = 100\n",
        "num_classes = 10  # CIFAR-10 a 10 classes\n",
        "img_size = 32  # CIFAR-10 a des images de 32x32\n",
        "channels = 3  # CIFAR-10 utilise des images RGB\n",
        "\n",
        "# Transformations pour prétraiter les données\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Charger les datasets CIFAR-10\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "# DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Modèle du générateur\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim, num_classes, img_size, channels):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.label_emb = nn.Embedding(num_classes, num_classes)  # Embedding pour les labels\n",
        "        self.init_size = img_size // 4  # Taille après le premier reshape\n",
        "\n",
        "        # Couche entièrement connectée pour projeter l'entrée (bruit + labels) en un tenseur spatial\n",
        "        self.l1 = nn.Sequential(\n",
        "            nn.Linear(latent_dim + num_classes, 128 * self.init_size ** 2)  # Projection dans un espace de caractéristiques\n",
        "        )\n",
        "\n",
        "        # Blocs convolutifs pour augmenter la taille de l'image\n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Upsample(scale_factor=2),  # Agrandir l'image spatialement\n",
        "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, channels, 3, stride=1, padding=1),\n",
        "            nn.Tanh()  # Normaliser les valeurs des pixels entre -1 et 1\n",
        "        )\n",
        "\n",
        "    def forward(self, noise, labels):\n",
        "        gen_input = torch.cat((noise, self.label_emb(labels)), -1)  # Concatenate noise et labels\n",
        "        out = self.l1(gen_input)\n",
        "        out = out.view(out.size(0), 128, self.init_size, self.init_size)  # Reshape pour correspondre aux convolutions\n",
        "        img = self.conv_blocks(out)\n",
        "        return img\n",
        "\n",
        "# Modèle du discriminateur\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, num_classes, img_size, channels):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.label_emb = nn.Embedding(num_classes, num_classes)  # Embedding pour les labels\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(num_classes + int(channels * img_size ** 2), 512),  # Combinaison image + label\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 1),\n",
        "            nn.Sigmoid()  # Probabilité de validité entre 0 et 1\n",
        "        )\n",
        "\n",
        "    def forward(self, img, labels):\n",
        "        d_in = torch.cat((img.view(img.size(0), -1), self.label_emb(labels)), -1)  # Mise à plat et concaténation des labels\n",
        "        validity = self.model(d_in)\n",
        "        return validity\n",
        "\n",
        "# Initialiser le générateur et le discriminateur\n",
        "generator = Generator(latent_dim, num_classes, img_size, channels).to(device)\n",
        "discriminator = Discriminator(num_classes, img_size, channels).to(device)\n",
        "\n",
        "# Optimiseurs\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "# Fonction de perte\n",
        "adversarial_loss = nn.BCELoss()\n",
        "\n",
        "# Fonction d'entraînement\n",
        "def train(epoch, num_epochs=100):\n",
        "    for i, (imgs, labels) in enumerate(train_loader):\n",
        "        batch_size = imgs.size(0)\n",
        "\n",
        "        # Labels réels et faux\n",
        "        real_labels = torch.ones(batch_size, 1).to(device)\n",
        "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
        "\n",
        "        # Envoi des images et des labels sur le GPU\n",
        "        imgs = imgs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Entraîner le générateur\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        noise = torch.randn(batch_size, latent_dim).to(device)\n",
        "        gen_imgs = generator(noise, labels)\n",
        "\n",
        "        g_loss = adversarial_loss(discriminator(gen_imgs, labels), real_labels)\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # Entraîner le discriminateur\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        real_loss = adversarial_loss(discriminator(imgs, labels), real_labels)\n",
        "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach(), labels), fake_labels)\n",
        "\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # Afficher les résultats toutes les 100 itérations\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Epoch [{epoch}/{num_epochs}] Batch [{i}/{len(train_loader)}] \"\n",
        "                  f\"Loss D: {d_loss.item()}, loss G: {g_loss.item()}\")\n",
        "\n",
        "\n",
        "# Démarrer l'entraînement\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    train(epoch, num_epochs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7Hrz1fuiE1o",
        "outputId": "c82be7ba-4342-4325-fccd-a28cd132ebcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch [0/100] Batch [0/782] Loss D: 0.6983076333999634, loss G: 0.6793653964996338\n",
            "Epoch [0/100] Batch [100/782] Loss D: 0.49126869440078735, loss G: 1.3020589351654053\n",
            "Epoch [0/100] Batch [200/782] Loss D: 0.5027440786361694, loss G: 0.9941338896751404\n",
            "Epoch [0/100] Batch [300/782] Loss D: 0.5828810930252075, loss G: 0.8753860592842102\n",
            "Epoch [0/100] Batch [400/782] Loss D: 0.5819929838180542, loss G: 1.2668203115463257\n",
            "Epoch [0/100] Batch [500/782] Loss D: 0.5775759220123291, loss G: 0.8693755865097046\n",
            "Epoch [0/100] Batch [600/782] Loss D: 0.6083483695983887, loss G: 0.9921460151672363\n",
            "Epoch [0/100] Batch [700/782] Loss D: 0.7204549312591553, loss G: 0.5799568891525269\n",
            "Epoch [1/100] Batch [0/782] Loss D: 0.6360500454902649, loss G: 0.8545852303504944\n",
            "Epoch [1/100] Batch [100/782] Loss D: 0.7423685193061829, loss G: 0.5756895542144775\n",
            "Epoch [1/100] Batch [200/782] Loss D: 0.6104924082756042, loss G: 0.8608089685440063\n",
            "Epoch [1/100] Batch [300/782] Loss D: 0.6790936589241028, loss G: 0.6831803321838379\n",
            "Epoch [1/100] Batch [400/782] Loss D: 0.6792311668395996, loss G: 0.7225436568260193\n",
            "Epoch [1/100] Batch [500/782] Loss D: 0.6546159982681274, loss G: 0.7706496119499207\n",
            "Epoch [1/100] Batch [600/782] Loss D: 0.720185399055481, loss G: 0.6911235451698303\n",
            "Epoch [1/100] Batch [700/782] Loss D: 0.649217963218689, loss G: 0.7780099511146545\n",
            "Epoch [2/100] Batch [0/782] Loss D: 0.7033276557922363, loss G: 0.6570265889167786\n",
            "Epoch [2/100] Batch [100/782] Loss D: 0.6760435104370117, loss G: 0.6856310367584229\n",
            "Epoch [2/100] Batch [200/782] Loss D: 0.6964185833930969, loss G: 0.6798648834228516\n",
            "Epoch [2/100] Batch [300/782] Loss D: 0.6678451299667358, loss G: 0.7643940448760986\n",
            "Epoch [2/100] Batch [400/782] Loss D: 0.6244943141937256, loss G: 0.7784626483917236\n",
            "Epoch [2/100] Batch [500/782] Loss D: 0.7483463287353516, loss G: 0.7757778167724609\n",
            "Epoch [2/100] Batch [600/782] Loss D: 0.6567808389663696, loss G: 0.6917862296104431\n",
            "Epoch [2/100] Batch [700/782] Loss D: 0.6844428777694702, loss G: 0.699111819267273\n",
            "Epoch [3/100] Batch [0/782] Loss D: 0.8193375468254089, loss G: 0.5460710525512695\n",
            "Epoch [3/100] Batch [100/782] Loss D: 0.6834562420845032, loss G: 0.6559371948242188\n",
            "Epoch [3/100] Batch [200/782] Loss D: 0.6729317903518677, loss G: 0.7987689971923828\n",
            "Epoch [3/100] Batch [300/782] Loss D: 0.732713520526886, loss G: 0.6113897562026978\n",
            "Epoch [3/100] Batch [400/782] Loss D: 0.6170953512191772, loss G: 0.7425583600997925\n",
            "Epoch [3/100] Batch [500/782] Loss D: 0.6234501600265503, loss G: 0.7858298420906067\n",
            "Epoch [3/100] Batch [600/782] Loss D: 0.6179257035255432, loss G: 0.8509528636932373\n",
            "Epoch [3/100] Batch [700/782] Loss D: 0.5958554148674011, loss G: 0.77410888671875\n",
            "Epoch [4/100] Batch [0/782] Loss D: 0.6441237926483154, loss G: 1.1016137599945068\n",
            "Epoch [4/100] Batch [100/782] Loss D: 0.4845251142978668, loss G: 1.078273057937622\n",
            "Epoch [4/100] Batch [200/782] Loss D: 0.6831946969032288, loss G: 0.6950017213821411\n",
            "Epoch [4/100] Batch [300/782] Loss D: 0.6691709160804749, loss G: 0.6874557137489319\n",
            "Epoch [4/100] Batch [400/782] Loss D: 0.6431571841239929, loss G: 0.9304515719413757\n",
            "Epoch [4/100] Batch [500/782] Loss D: 0.671593189239502, loss G: 0.7678015232086182\n",
            "Epoch [4/100] Batch [600/782] Loss D: 0.6834772825241089, loss G: 0.7187790274620056\n",
            "Epoch [4/100] Batch [700/782] Loss D: 0.6535396575927734, loss G: 0.7252972722053528\n",
            "Epoch [5/100] Batch [0/782] Loss D: 0.6267735958099365, loss G: 0.8791338801383972\n",
            "Epoch [5/100] Batch [100/782] Loss D: 0.6193612217903137, loss G: 1.2669711112976074\n",
            "Epoch [5/100] Batch [200/782] Loss D: 0.6391162872314453, loss G: 0.838139533996582\n",
            "Epoch [5/100] Batch [300/782] Loss D: 0.6585272550582886, loss G: 0.7167895436286926\n",
            "Epoch [5/100] Batch [400/782] Loss D: 0.6328211426734924, loss G: 0.8093973994255066\n",
            "Epoch [5/100] Batch [500/782] Loss D: 0.6209784150123596, loss G: 0.924586296081543\n",
            "Epoch [5/100] Batch [600/782] Loss D: 0.5763729810714722, loss G: 0.825574517250061\n",
            "Epoch [5/100] Batch [700/782] Loss D: 0.6711217164993286, loss G: 0.9296485185623169\n",
            "Epoch [6/100] Batch [0/782] Loss D: 0.6397565007209778, loss G: 0.7788741588592529\n",
            "Epoch [6/100] Batch [100/782] Loss D: 0.670629620552063, loss G: 0.7046582698822021\n",
            "Epoch [6/100] Batch [200/782] Loss D: 0.6598042249679565, loss G: 0.9519182443618774\n",
            "Epoch [6/100] Batch [300/782] Loss D: 0.6890867948532104, loss G: 0.7654013633728027\n",
            "Epoch [6/100] Batch [400/782] Loss D: 0.6407496333122253, loss G: 0.7403528690338135\n",
            "Epoch [6/100] Batch [500/782] Loss D: 0.6527544260025024, loss G: 0.8306570053100586\n",
            "Epoch [6/100] Batch [600/782] Loss D: 0.7116439938545227, loss G: 0.7360857129096985\n",
            "Epoch [6/100] Batch [700/782] Loss D: 0.740503191947937, loss G: 0.6487699747085571\n",
            "Epoch [7/100] Batch [0/782] Loss D: 0.6762795448303223, loss G: 0.6938602924346924\n",
            "Epoch [7/100] Batch [100/782] Loss D: 0.5890017747879028, loss G: 0.8102716207504272\n",
            "Epoch [7/100] Batch [200/782] Loss D: 0.6562765836715698, loss G: 0.7073657512664795\n",
            "Epoch [7/100] Batch [300/782] Loss D: 0.664612889289856, loss G: 0.9458210468292236\n",
            "Epoch [7/100] Batch [400/782] Loss D: 0.6306999921798706, loss G: 0.8445162773132324\n",
            "Epoch [7/100] Batch [500/782] Loss D: 0.6696012020111084, loss G: 0.8614733219146729\n",
            "Epoch [7/100] Batch [600/782] Loss D: 0.6505683660507202, loss G: 0.8130586743354797\n",
            "Epoch [7/100] Batch [700/782] Loss D: 0.6845937967300415, loss G: 0.7999172806739807\n",
            "Epoch [8/100] Batch [0/782] Loss D: 0.7166965007781982, loss G: 0.6950107216835022\n",
            "Epoch [8/100] Batch [100/782] Loss D: 0.6600040197372437, loss G: 0.7533833980560303\n",
            "Epoch [8/100] Batch [200/782] Loss D: 0.6700727939605713, loss G: 0.9488997459411621\n",
            "Epoch [8/100] Batch [300/782] Loss D: 0.6653941869735718, loss G: 0.7136319875717163\n",
            "Epoch [8/100] Batch [400/782] Loss D: 0.6859544515609741, loss G: 0.745029866695404\n",
            "Epoch [8/100] Batch [500/782] Loss D: 0.6663426756858826, loss G: 0.7730599641799927\n",
            "Epoch [8/100] Batch [600/782] Loss D: 0.6609188318252563, loss G: 0.8358244299888611\n",
            "Epoch [8/100] Batch [700/782] Loss D: 0.6582868099212646, loss G: 0.8118249177932739\n",
            "Epoch [9/100] Batch [0/782] Loss D: 0.6815006732940674, loss G: 0.7340590357780457\n",
            "Epoch [9/100] Batch [100/782] Loss D: 0.6646219491958618, loss G: 0.7208436131477356\n",
            "Epoch [9/100] Batch [200/782] Loss D: 0.6968026161193848, loss G: 0.6896374821662903\n",
            "Epoch [9/100] Batch [300/782] Loss D: 0.6543549299240112, loss G: 0.8053323030471802\n",
            "Epoch [9/100] Batch [400/782] Loss D: 0.7142064571380615, loss G: 0.7103779315948486\n",
            "Epoch [9/100] Batch [500/782] Loss D: 0.6575783491134644, loss G: 0.8063173294067383\n",
            "Epoch [9/100] Batch [600/782] Loss D: 0.6905148029327393, loss G: 0.7838320732116699\n",
            "Epoch [9/100] Batch [700/782] Loss D: 0.6832982301712036, loss G: 0.6883636116981506\n",
            "Epoch [10/100] Batch [0/782] Loss D: 0.6561079025268555, loss G: 0.7799047231674194\n",
            "Epoch [10/100] Batch [100/782] Loss D: 0.6892218589782715, loss G: 0.6757519245147705\n",
            "Epoch [10/100] Batch [200/782] Loss D: 0.6621650457382202, loss G: 0.7931420803070068\n",
            "Epoch [10/100] Batch [300/782] Loss D: 0.6758444905281067, loss G: 0.7115669846534729\n",
            "Epoch [10/100] Batch [400/782] Loss D: 0.7077449560165405, loss G: 0.615970253944397\n",
            "Epoch [10/100] Batch [500/782] Loss D: 0.7102333307266235, loss G: 0.6552284955978394\n",
            "Epoch [10/100] Batch [600/782] Loss D: 0.6903554201126099, loss G: 0.774126410484314\n",
            "Epoch [10/100] Batch [700/782] Loss D: 0.6712589859962463, loss G: 0.6679977774620056\n",
            "Epoch [11/100] Batch [0/782] Loss D: 0.6905045509338379, loss G: 0.6816551685333252\n",
            "Epoch [11/100] Batch [100/782] Loss D: 0.7016868591308594, loss G: 0.7665637731552124\n",
            "Epoch [11/100] Batch [200/782] Loss D: 0.6738286018371582, loss G: 0.7328037023544312\n",
            "Epoch [11/100] Batch [300/782] Loss D: 0.6753790378570557, loss G: 0.8294061422348022\n",
            "Epoch [11/100] Batch [400/782] Loss D: 0.6505101323127747, loss G: 0.8082258105278015\n",
            "Epoch [11/100] Batch [500/782] Loss D: 0.6791607141494751, loss G: 0.797231137752533\n",
            "Epoch [11/100] Batch [600/782] Loss D: 0.6675596237182617, loss G: 0.7604049444198608\n",
            "Epoch [11/100] Batch [700/782] Loss D: 0.6538683176040649, loss G: 0.7860639691352844\n",
            "Epoch [12/100] Batch [0/782] Loss D: 0.6463561058044434, loss G: 0.7639082670211792\n",
            "Epoch [12/100] Batch [100/782] Loss D: 0.6380838751792908, loss G: 0.8427701592445374\n",
            "Epoch [12/100] Batch [200/782] Loss D: 0.6621307730674744, loss G: 0.7549710273742676\n",
            "Epoch [12/100] Batch [300/782] Loss D: 0.7123176455497742, loss G: 0.657865583896637\n",
            "Epoch [12/100] Batch [400/782] Loss D: 0.7024659514427185, loss G: 0.7120546102523804\n",
            "Epoch [12/100] Batch [500/782] Loss D: 0.6983033418655396, loss G: 0.7691004872322083\n",
            "Epoch [12/100] Batch [600/782] Loss D: 0.6703639626502991, loss G: 0.6918008327484131\n",
            "Epoch [12/100] Batch [700/782] Loss D: 0.7218203544616699, loss G: 0.7017192840576172\n",
            "Epoch [13/100] Batch [0/782] Loss D: 0.6732735633850098, loss G: 0.7131324410438538\n",
            "Epoch [13/100] Batch [100/782] Loss D: 0.6657850742340088, loss G: 0.7611390352249146\n",
            "Epoch [13/100] Batch [200/782] Loss D: 0.6540089845657349, loss G: 0.7444592714309692\n",
            "Epoch [13/100] Batch [300/782] Loss D: 0.709241509437561, loss G: 0.7144650220870972\n",
            "Epoch [13/100] Batch [400/782] Loss D: 0.6876486539840698, loss G: 0.7427405118942261\n",
            "Epoch [13/100] Batch [500/782] Loss D: 0.6258468627929688, loss G: 0.7880594730377197\n",
            "Epoch [13/100] Batch [600/782] Loss D: 0.67585289478302, loss G: 0.7120819091796875\n",
            "Epoch [13/100] Batch [700/782] Loss D: 0.6951791048049927, loss G: 0.6678119897842407\n",
            "Epoch [14/100] Batch [0/782] Loss D: 0.7116639614105225, loss G: 0.7107968330383301\n",
            "Epoch [14/100] Batch [100/782] Loss D: 0.6901993155479431, loss G: 0.7782925963401794\n",
            "Epoch [14/100] Batch [200/782] Loss D: 0.6597545146942139, loss G: 0.684337854385376\n",
            "Epoch [14/100] Batch [300/782] Loss D: 0.6773045063018799, loss G: 0.7823430299758911\n",
            "Epoch [14/100] Batch [400/782] Loss D: 0.6553328037261963, loss G: 0.7511216402053833\n",
            "Epoch [14/100] Batch [500/782] Loss D: 0.7272593975067139, loss G: 0.7110477685928345\n",
            "Epoch [14/100] Batch [600/782] Loss D: 0.6827239990234375, loss G: 0.7898687124252319\n",
            "Epoch [14/100] Batch [700/782] Loss D: 0.6806225776672363, loss G: 0.77892005443573\n",
            "Epoch [15/100] Batch [0/782] Loss D: 0.6556870341300964, loss G: 0.779704213142395\n",
            "Epoch [15/100] Batch [100/782] Loss D: 0.6882079839706421, loss G: 0.7384952306747437\n",
            "Epoch [15/100] Batch [200/782] Loss D: 0.669479489326477, loss G: 0.784032940864563\n",
            "Epoch [15/100] Batch [300/782] Loss D: 0.673150897026062, loss G: 0.7623244524002075\n",
            "Epoch [15/100] Batch [400/782] Loss D: 0.6991005539894104, loss G: 0.7211797833442688\n",
            "Epoch [15/100] Batch [500/782] Loss D: 0.6932598352432251, loss G: 0.7322594523429871\n",
            "Epoch [15/100] Batch [600/782] Loss D: 0.6869350671768188, loss G: 0.7734403610229492\n",
            "Epoch [15/100] Batch [700/782] Loss D: 0.708106517791748, loss G: 0.7030293941497803\n",
            "Epoch [16/100] Batch [0/782] Loss D: 0.7018489241600037, loss G: 0.7191418409347534\n",
            "Epoch [16/100] Batch [100/782] Loss D: 0.6946157217025757, loss G: 0.6955370903015137\n",
            "Epoch [16/100] Batch [200/782] Loss D: 0.6547291874885559, loss G: 0.8730641007423401\n",
            "Epoch [16/100] Batch [300/782] Loss D: 0.6522765159606934, loss G: 0.786925733089447\n",
            "Epoch [16/100] Batch [400/782] Loss D: 0.7026416063308716, loss G: 0.6732267141342163\n",
            "Epoch [16/100] Batch [500/782] Loss D: 0.6834967136383057, loss G: 0.7067538499832153\n",
            "Epoch [16/100] Batch [600/782] Loss D: 0.6910337209701538, loss G: 0.7398306131362915\n",
            "Epoch [16/100] Batch [700/782] Loss D: 0.6385300755500793, loss G: 0.8088460564613342\n",
            "Epoch [17/100] Batch [0/782] Loss D: 0.6958587169647217, loss G: 0.6542876958847046\n",
            "Epoch [17/100] Batch [100/782] Loss D: 0.6721006631851196, loss G: 0.7333475351333618\n",
            "Epoch [17/100] Batch [200/782] Loss D: 0.6623700261116028, loss G: 0.7960965633392334\n",
            "Epoch [17/100] Batch [300/782] Loss D: 0.706390380859375, loss G: 0.7284566164016724\n",
            "Epoch [17/100] Batch [400/782] Loss D: 0.6731137037277222, loss G: 0.7283796072006226\n",
            "Epoch [17/100] Batch [500/782] Loss D: 0.6758778095245361, loss G: 0.7114372253417969\n",
            "Epoch [17/100] Batch [600/782] Loss D: 0.7133558392524719, loss G: 0.7020495533943176\n",
            "Epoch [17/100] Batch [700/782] Loss D: 0.6719620227813721, loss G: 0.7345972061157227\n",
            "Epoch [18/100] Batch [0/782] Loss D: 0.6374611854553223, loss G: 0.8326846361160278\n",
            "Epoch [18/100] Batch [100/782] Loss D: 0.6742298007011414, loss G: 0.8054369688034058\n",
            "Epoch [18/100] Batch [200/782] Loss D: 0.6743600964546204, loss G: 0.7423596382141113\n",
            "Epoch [18/100] Batch [300/782] Loss D: 0.6594243049621582, loss G: 0.8524528741836548\n",
            "Epoch [18/100] Batch [400/782] Loss D: 0.6745326519012451, loss G: 0.7417430877685547\n",
            "Epoch [18/100] Batch [500/782] Loss D: 0.6608129739761353, loss G: 0.7433884739875793\n",
            "Epoch [18/100] Batch [600/782] Loss D: 0.6561633348464966, loss G: 0.7074198722839355\n",
            "Epoch [18/100] Batch [700/782] Loss D: 0.6713169813156128, loss G: 0.8130762577056885\n",
            "Epoch [19/100] Batch [0/782] Loss D: 0.6541651487350464, loss G: 0.7557122111320496\n",
            "Epoch [19/100] Batch [100/782] Loss D: 0.6708187460899353, loss G: 0.7574856877326965\n",
            "Epoch [19/100] Batch [200/782] Loss D: 0.6461864113807678, loss G: 0.7873437404632568\n",
            "Epoch [19/100] Batch [300/782] Loss D: 0.6942155361175537, loss G: 0.7343177795410156\n",
            "Epoch [19/100] Batch [400/782] Loss D: 0.6892671585083008, loss G: 0.7297486066818237\n",
            "Epoch [19/100] Batch [500/782] Loss D: 0.6969317197799683, loss G: 0.7289485931396484\n",
            "Epoch [19/100] Batch [600/782] Loss D: 0.6607180833816528, loss G: 0.786018967628479\n",
            "Epoch [19/100] Batch [700/782] Loss D: 0.639099657535553, loss G: 0.7640544176101685\n",
            "Epoch [20/100] Batch [0/782] Loss D: 0.6948075890541077, loss G: 0.652280330657959\n",
            "Epoch [20/100] Batch [100/782] Loss D: 0.6948651075363159, loss G: 0.7839084267616272\n",
            "Epoch [20/100] Batch [200/782] Loss D: 0.658901572227478, loss G: 0.761314868927002\n",
            "Epoch [20/100] Batch [300/782] Loss D: 0.6934521198272705, loss G: 0.7565372586250305\n",
            "Epoch [20/100] Batch [400/782] Loss D: 0.6632163524627686, loss G: 0.7364526987075806\n",
            "Epoch [20/100] Batch [500/782] Loss D: 0.6615502834320068, loss G: 0.8281769156455994\n",
            "Epoch [20/100] Batch [600/782] Loss D: 0.6782664060592651, loss G: 0.7453937530517578\n",
            "Epoch [20/100] Batch [700/782] Loss D: 0.6914480328559875, loss G: 0.7360395193099976\n",
            "Epoch [21/100] Batch [0/782] Loss D: 0.6668365597724915, loss G: 0.7277474403381348\n",
            "Epoch [21/100] Batch [100/782] Loss D: 0.6592140197753906, loss G: 0.7474839091300964\n",
            "Epoch [21/100] Batch [200/782] Loss D: 0.6932651400566101, loss G: 0.7469319701194763\n",
            "Epoch [21/100] Batch [300/782] Loss D: 0.6867464780807495, loss G: 0.6839311122894287\n",
            "Epoch [21/100] Batch [400/782] Loss D: 0.6821387410163879, loss G: 0.7467835545539856\n",
            "Epoch [21/100] Batch [500/782] Loss D: 0.6775449514389038, loss G: 0.7986071109771729\n",
            "Epoch [21/100] Batch [600/782] Loss D: 0.7036498785018921, loss G: 0.6852137446403503\n",
            "Epoch [21/100] Batch [700/782] Loss D: 0.627454400062561, loss G: 0.7872047424316406\n",
            "Epoch [22/100] Batch [0/782] Loss D: 0.6862893104553223, loss G: 0.777526319026947\n",
            "Epoch [22/100] Batch [100/782] Loss D: 0.6497843265533447, loss G: 0.7536205053329468\n",
            "Epoch [22/100] Batch [200/782] Loss D: 0.6429873704910278, loss G: 0.7541430592536926\n",
            "Epoch [22/100] Batch [300/782] Loss D: 0.6655508279800415, loss G: 0.7832486629486084\n",
            "Epoch [22/100] Batch [400/782] Loss D: 0.6917431950569153, loss G: 0.747625470161438\n",
            "Epoch [22/100] Batch [500/782] Loss D: 0.6767346858978271, loss G: 0.7184411287307739\n",
            "Epoch [22/100] Batch [600/782] Loss D: 0.6566157341003418, loss G: 0.7844661474227905\n",
            "Epoch [22/100] Batch [700/782] Loss D: 0.7107626795768738, loss G: 0.7093886733055115\n",
            "Epoch [23/100] Batch [0/782] Loss D: 0.683179497718811, loss G: 0.7272603511810303\n",
            "Epoch [23/100] Batch [100/782] Loss D: 0.6581177711486816, loss G: 0.8136370778083801\n",
            "Epoch [23/100] Batch [200/782] Loss D: 0.6529678106307983, loss G: 0.7324819564819336\n",
            "Epoch [23/100] Batch [300/782] Loss D: 0.6803675889968872, loss G: 0.6989129781723022\n",
            "Epoch [23/100] Batch [400/782] Loss D: 0.6435827016830444, loss G: 0.7720860242843628\n",
            "Epoch [23/100] Batch [500/782] Loss D: 0.7013634443283081, loss G: 0.7334009408950806\n",
            "Epoch [23/100] Batch [600/782] Loss D: 0.6818623542785645, loss G: 0.7677465677261353\n",
            "Epoch [23/100] Batch [700/782] Loss D: 0.6666343212127686, loss G: 0.6888704299926758\n",
            "Epoch [24/100] Batch [0/782] Loss D: 0.6724078059196472, loss G: 0.8166440725326538\n",
            "Epoch [24/100] Batch [100/782] Loss D: 0.6600028872489929, loss G: 0.7319779992103577\n",
            "Epoch [24/100] Batch [200/782] Loss D: 0.7203661799430847, loss G: 0.677108645439148\n",
            "Epoch [24/100] Batch [300/782] Loss D: 0.6547947525978088, loss G: 0.7492944002151489\n",
            "Epoch [24/100] Batch [400/782] Loss D: 0.6755956411361694, loss G: 0.758485734462738\n",
            "Epoch [24/100] Batch [500/782] Loss D: 0.6610292196273804, loss G: 0.7631354928016663\n",
            "Epoch [24/100] Batch [600/782] Loss D: 0.6860513687133789, loss G: 0.7824276685714722\n",
            "Epoch [24/100] Batch [700/782] Loss D: 0.6838041543960571, loss G: 0.6908726692199707\n",
            "Epoch [25/100] Batch [0/782] Loss D: 0.6462337970733643, loss G: 0.7473384737968445\n",
            "Epoch [25/100] Batch [100/782] Loss D: 0.6840710639953613, loss G: 0.7381289005279541\n",
            "Epoch [25/100] Batch [200/782] Loss D: 0.6478158235549927, loss G: 0.7930311560630798\n",
            "Epoch [25/100] Batch [300/782] Loss D: 0.6550877094268799, loss G: 0.8048644065856934\n",
            "Epoch [25/100] Batch [400/782] Loss D: 0.6845341920852661, loss G: 0.6813675165176392\n",
            "Epoch [25/100] Batch [500/782] Loss D: 0.6455420255661011, loss G: 0.7281472682952881\n",
            "Epoch [25/100] Batch [600/782] Loss D: 0.6679648160934448, loss G: 0.8239314556121826\n",
            "Epoch [25/100] Batch [700/782] Loss D: 0.7068110704421997, loss G: 0.7445173263549805\n",
            "Epoch [26/100] Batch [0/782] Loss D: 0.6791843175888062, loss G: 0.7034657001495361\n",
            "Epoch [26/100] Batch [100/782] Loss D: 0.6900033354759216, loss G: 0.8097151517868042\n",
            "Epoch [26/100] Batch [200/782] Loss D: 0.66512531042099, loss G: 0.7703136801719666\n",
            "Epoch [26/100] Batch [300/782] Loss D: 0.6716418266296387, loss G: 0.7492966055870056\n",
            "Epoch [26/100] Batch [400/782] Loss D: 0.6934551000595093, loss G: 0.7399588227272034\n",
            "Epoch [26/100] Batch [500/782] Loss D: 0.6760695576667786, loss G: 0.7866195440292358\n",
            "Epoch [26/100] Batch [600/782] Loss D: 0.6514526009559631, loss G: 0.7429209351539612\n",
            "Epoch [26/100] Batch [700/782] Loss D: 0.6705400943756104, loss G: 0.7735240459442139\n",
            "Epoch [27/100] Batch [0/782] Loss D: 0.6778263449668884, loss G: 0.7425835132598877\n",
            "Epoch [27/100] Batch [100/782] Loss D: 0.6606677174568176, loss G: 0.7371066808700562\n",
            "Epoch [27/100] Batch [200/782] Loss D: 0.6920269131660461, loss G: 0.7984335422515869\n",
            "Epoch [27/100] Batch [300/782] Loss D: 0.6673004627227783, loss G: 0.7644728422164917\n",
            "Epoch [27/100] Batch [400/782] Loss D: 0.6428850293159485, loss G: 0.8379923701286316\n",
            "Epoch [27/100] Batch [500/782] Loss D: 0.6512677669525146, loss G: 0.7612386345863342\n",
            "Epoch [27/100] Batch [600/782] Loss D: 0.6764732599258423, loss G: 0.7287768125534058\n",
            "Epoch [27/100] Batch [700/782] Loss D: 0.6785019636154175, loss G: 0.7720597982406616\n",
            "Epoch [28/100] Batch [0/782] Loss D: 0.6645141243934631, loss G: 0.7648698091506958\n",
            "Epoch [28/100] Batch [100/782] Loss D: 0.6774469614028931, loss G: 0.6890953779220581\n",
            "Epoch [28/100] Batch [200/782] Loss D: 0.6691860556602478, loss G: 0.723010778427124\n",
            "Epoch [28/100] Batch [300/782] Loss D: 0.6782795786857605, loss G: 0.7640479803085327\n",
            "Epoch [28/100] Batch [400/782] Loss D: 0.6643199920654297, loss G: 0.7326172590255737\n",
            "Epoch [28/100] Batch [500/782] Loss D: 0.6689854264259338, loss G: 0.7261679172515869\n",
            "Epoch [28/100] Batch [600/782] Loss D: 0.6749786138534546, loss G: 0.7313530445098877\n",
            "Epoch [28/100] Batch [700/782] Loss D: 0.6722515821456909, loss G: 0.856775164604187\n",
            "Epoch [29/100] Batch [0/782] Loss D: 0.6672646999359131, loss G: 0.7284864783287048\n",
            "Epoch [29/100] Batch [100/782] Loss D: 0.6472177505493164, loss G: 0.7441755533218384\n",
            "Epoch [29/100] Batch [200/782] Loss D: 0.6867146492004395, loss G: 0.6938684582710266\n",
            "Epoch [29/100] Batch [300/782] Loss D: 0.6876194477081299, loss G: 0.7848681211471558\n",
            "Epoch [29/100] Batch [400/782] Loss D: 0.7368469834327698, loss G: 0.7127021551132202\n",
            "Epoch [29/100] Batch [500/782] Loss D: 0.6872108578681946, loss G: 0.7190587520599365\n",
            "Epoch [29/100] Batch [600/782] Loss D: 0.6341173648834229, loss G: 0.8012922406196594\n",
            "Epoch [29/100] Batch [700/782] Loss D: 0.6626065969467163, loss G: 0.7044328451156616\n",
            "Epoch [30/100] Batch [0/782] Loss D: 0.6938033699989319, loss G: 0.7075310945510864\n",
            "Epoch [30/100] Batch [100/782] Loss D: 0.6548134088516235, loss G: 0.7886378765106201\n",
            "Epoch [30/100] Batch [200/782] Loss D: 0.6805442571640015, loss G: 0.6925516128540039\n",
            "Epoch [30/100] Batch [300/782] Loss D: 0.6444367170333862, loss G: 0.7072702050209045\n",
            "Epoch [30/100] Batch [400/782] Loss D: 0.6878446340560913, loss G: 0.7885645031929016\n",
            "Epoch [30/100] Batch [500/782] Loss D: 0.6734106540679932, loss G: 0.7178179621696472\n",
            "Epoch [30/100] Batch [600/782] Loss D: 0.6987311840057373, loss G: 0.7310556769371033\n",
            "Epoch [30/100] Batch [700/782] Loss D: 0.6819474697113037, loss G: 0.745403528213501\n",
            "Epoch [31/100] Batch [0/782] Loss D: 0.6574935913085938, loss G: 0.7716110944747925\n",
            "Epoch [31/100] Batch [100/782] Loss D: 0.6934942007064819, loss G: 0.683678388595581\n",
            "Epoch [31/100] Batch [200/782] Loss D: 0.6574968099594116, loss G: 0.7804738879203796\n",
            "Epoch [31/100] Batch [300/782] Loss D: 0.7105836272239685, loss G: 0.7094421982765198\n",
            "Epoch [31/100] Batch [400/782] Loss D: 0.6776731014251709, loss G: 0.7413403391838074\n",
            "Epoch [31/100] Batch [500/782] Loss D: 0.6554121971130371, loss G: 0.8277137279510498\n",
            "Epoch [31/100] Batch [600/782] Loss D: 0.6681776642799377, loss G: 0.7031134963035583\n",
            "Epoch [31/100] Batch [700/782] Loss D: 0.6640427112579346, loss G: 0.7903735041618347\n",
            "Epoch [32/100] Batch [0/782] Loss D: 0.6519701480865479, loss G: 0.7898362874984741\n",
            "Epoch [32/100] Batch [100/782] Loss D: 0.6719998121261597, loss G: 0.7591473460197449\n",
            "Epoch [32/100] Batch [200/782] Loss D: 0.682451605796814, loss G: 0.7268773913383484\n",
            "Epoch [32/100] Batch [300/782] Loss D: 0.6791393756866455, loss G: 0.7576135396957397\n",
            "Epoch [32/100] Batch [400/782] Loss D: 0.6788066625595093, loss G: 0.7394023537635803\n",
            "Epoch [32/100] Batch [500/782] Loss D: 0.6947081089019775, loss G: 0.7701741456985474\n",
            "Epoch [32/100] Batch [600/782] Loss D: 0.661332368850708, loss G: 0.729204535484314\n",
            "Epoch [32/100] Batch [700/782] Loss D: 0.6904754638671875, loss G: 0.7442694902420044\n",
            "Epoch [33/100] Batch [0/782] Loss D: 0.6982235908508301, loss G: 0.7195737361907959\n",
            "Epoch [33/100] Batch [100/782] Loss D: 0.6347749829292297, loss G: 0.8101766705513\n",
            "Epoch [33/100] Batch [200/782] Loss D: 0.6737690567970276, loss G: 0.7342433929443359\n",
            "Epoch [33/100] Batch [300/782] Loss D: 0.6913727521896362, loss G: 0.7171547412872314\n",
            "Epoch [33/100] Batch [400/782] Loss D: 0.6367717981338501, loss G: 0.7792989015579224\n",
            "Epoch [33/100] Batch [500/782] Loss D: 0.684916615486145, loss G: 0.6872837543487549\n",
            "Epoch [33/100] Batch [600/782] Loss D: 0.6635192632675171, loss G: 0.6995538473129272\n",
            "Epoch [33/100] Batch [700/782] Loss D: 0.6902316808700562, loss G: 0.74595046043396\n",
            "Epoch [34/100] Batch [0/782] Loss D: 0.6791108846664429, loss G: 0.6852758526802063\n",
            "Epoch [34/100] Batch [100/782] Loss D: 0.6677039861679077, loss G: 0.7307923436164856\n",
            "Epoch [34/100] Batch [200/782] Loss D: 0.6662859320640564, loss G: 0.795528769493103\n",
            "Epoch [34/100] Batch [300/782] Loss D: 0.7003493309020996, loss G: 0.7069516181945801\n",
            "Epoch [34/100] Batch [400/782] Loss D: 0.7116698026657104, loss G: 0.7162449359893799\n",
            "Epoch [34/100] Batch [500/782] Loss D: 0.6585961580276489, loss G: 0.7361551523208618\n",
            "Epoch [34/100] Batch [600/782] Loss D: 0.6718940138816833, loss G: 0.7739138603210449\n",
            "Epoch [34/100] Batch [700/782] Loss D: 0.6711375117301941, loss G: 0.7397031784057617\n",
            "Epoch [35/100] Batch [0/782] Loss D: 0.6798136830329895, loss G: 0.7566392421722412\n",
            "Epoch [35/100] Batch [100/782] Loss D: 0.662110447883606, loss G: 0.7326657176017761\n",
            "Epoch [35/100] Batch [200/782] Loss D: 0.6765662431716919, loss G: 0.7655079364776611\n",
            "Epoch [35/100] Batch [300/782] Loss D: 0.6847399473190308, loss G: 0.762604832649231\n",
            "Epoch [35/100] Batch [400/782] Loss D: 0.6846133470535278, loss G: 0.689425528049469\n",
            "Epoch [35/100] Batch [500/782] Loss D: 0.6857829689979553, loss G: 0.7100553512573242\n",
            "Epoch [35/100] Batch [600/782] Loss D: 0.6424903869628906, loss G: 0.8341001272201538\n",
            "Epoch [35/100] Batch [700/782] Loss D: 0.6756069660186768, loss G: 0.777660071849823\n",
            "Epoch [36/100] Batch [0/782] Loss D: 0.7051630020141602, loss G: 0.7910652160644531\n",
            "Epoch [36/100] Batch [100/782] Loss D: 0.6430466175079346, loss G: 0.8430608510971069\n",
            "Epoch [36/100] Batch [200/782] Loss D: 0.663818359375, loss G: 0.7016695737838745\n",
            "Epoch [36/100] Batch [300/782] Loss D: 0.6773484945297241, loss G: 0.7016480565071106\n",
            "Epoch [36/100] Batch [400/782] Loss D: 0.6663368940353394, loss G: 0.767845869064331\n",
            "Epoch [36/100] Batch [500/782] Loss D: 0.6690142154693604, loss G: 0.7399892807006836\n",
            "Epoch [36/100] Batch [600/782] Loss D: 0.6774848699569702, loss G: 0.6947826147079468\n",
            "Epoch [36/100] Batch [700/782] Loss D: 0.6602146625518799, loss G: 0.7623845338821411\n",
            "Epoch [37/100] Batch [0/782] Loss D: 0.6952203512191772, loss G: 0.7464056611061096\n",
            "Epoch [37/100] Batch [100/782] Loss D: 0.653955340385437, loss G: 0.7619994878768921\n",
            "Epoch [37/100] Batch [200/782] Loss D: 0.6708131432533264, loss G: 0.7160282731056213\n",
            "Epoch [37/100] Batch [300/782] Loss D: 0.6747318506240845, loss G: 0.7595093846321106\n",
            "Epoch [37/100] Batch [400/782] Loss D: 0.6492586731910706, loss G: 0.7929618954658508\n",
            "Epoch [37/100] Batch [500/782] Loss D: 0.6590771079063416, loss G: 0.7272640466690063\n",
            "Epoch [37/100] Batch [600/782] Loss D: 0.6490123271942139, loss G: 0.7342627644538879\n",
            "Epoch [37/100] Batch [700/782] Loss D: 0.6771962642669678, loss G: 0.7582505345344543\n",
            "Epoch [38/100] Batch [0/782] Loss D: 0.6643242239952087, loss G: 0.7982310056686401\n",
            "Epoch [38/100] Batch [100/782] Loss D: 0.6904191970825195, loss G: 0.7212401628494263\n",
            "Epoch [38/100] Batch [200/782] Loss D: 0.6757662296295166, loss G: 0.7057961225509644\n",
            "Epoch [38/100] Batch [300/782] Loss D: 0.6680145263671875, loss G: 0.7301021814346313\n",
            "Epoch [38/100] Batch [400/782] Loss D: 0.6607204079627991, loss G: 0.7394770979881287\n",
            "Epoch [38/100] Batch [500/782] Loss D: 0.6787674427032471, loss G: 0.7563672065734863\n",
            "Epoch [38/100] Batch [600/782] Loss D: 0.654346227645874, loss G: 0.7212879061698914\n",
            "Epoch [38/100] Batch [700/782] Loss D: 0.7150800228118896, loss G: 0.6836904287338257\n",
            "Epoch [39/100] Batch [0/782] Loss D: 0.6784161329269409, loss G: 0.7082071304321289\n",
            "Epoch [39/100] Batch [100/782] Loss D: 0.7083926796913147, loss G: 0.6721352338790894\n",
            "Epoch [39/100] Batch [200/782] Loss D: 0.6678496599197388, loss G: 0.789167582988739\n",
            "Epoch [39/100] Batch [300/782] Loss D: 0.6835009455680847, loss G: 0.7956808805465698\n",
            "Epoch [39/100] Batch [400/782] Loss D: 0.6713461875915527, loss G: 0.7315241098403931\n",
            "Epoch [39/100] Batch [500/782] Loss D: 0.6702979207038879, loss G: 0.7787075042724609\n",
            "Epoch [39/100] Batch [600/782] Loss D: 0.6756637096405029, loss G: 0.7161204218864441\n",
            "Epoch [39/100] Batch [700/782] Loss D: 0.6701735258102417, loss G: 0.7127826809883118\n",
            "Epoch [40/100] Batch [0/782] Loss D: 0.6834708452224731, loss G: 0.8062906265258789\n",
            "Epoch [40/100] Batch [100/782] Loss D: 0.658578097820282, loss G: 0.8050053715705872\n",
            "Epoch [40/100] Batch [200/782] Loss D: 0.7142605185508728, loss G: 0.724133312702179\n",
            "Epoch [40/100] Batch [300/782] Loss D: 0.68043452501297, loss G: 0.7912262678146362\n",
            "Epoch [40/100] Batch [400/782] Loss D: 0.7071166634559631, loss G: 0.7505151033401489\n",
            "Epoch [40/100] Batch [500/782] Loss D: 0.6675402522087097, loss G: 0.7341479063034058\n",
            "Epoch [40/100] Batch [600/782] Loss D: 0.6816988587379456, loss G: 0.730864405632019\n",
            "Epoch [40/100] Batch [700/782] Loss D: 0.6781592965126038, loss G: 0.7527549266815186\n",
            "Epoch [41/100] Batch [0/782] Loss D: 0.6844509840011597, loss G: 0.7410116195678711\n",
            "Epoch [41/100] Batch [100/782] Loss D: 0.7239927649497986, loss G: 0.7125676870346069\n",
            "Epoch [41/100] Batch [200/782] Loss D: 0.6800098419189453, loss G: 0.7002884149551392\n",
            "Epoch [41/100] Batch [300/782] Loss D: 0.6551719903945923, loss G: 0.7210816144943237\n",
            "Epoch [41/100] Batch [400/782] Loss D: 0.6731407046318054, loss G: 0.7604309916496277\n",
            "Epoch [41/100] Batch [500/782] Loss D: 0.6928592920303345, loss G: 0.7423526048660278\n",
            "Epoch [41/100] Batch [600/782] Loss D: 0.6711364388465881, loss G: 0.8006419539451599\n",
            "Epoch [41/100] Batch [700/782] Loss D: 0.6756954193115234, loss G: 0.6941020488739014\n",
            "Epoch [42/100] Batch [0/782] Loss D: 0.6751648783683777, loss G: 0.6898940801620483\n",
            "Epoch [42/100] Batch [100/782] Loss D: 0.6986837983131409, loss G: 0.735442042350769\n",
            "Epoch [42/100] Batch [200/782] Loss D: 0.6529343724250793, loss G: 0.7573655843734741\n",
            "Epoch [42/100] Batch [300/782] Loss D: 0.6716504096984863, loss G: 0.7643213868141174\n",
            "Epoch [42/100] Batch [400/782] Loss D: 0.6830205321311951, loss G: 0.7670923471450806\n",
            "Epoch [42/100] Batch [500/782] Loss D: 0.6763213276863098, loss G: 0.7522399425506592\n",
            "Epoch [42/100] Batch [600/782] Loss D: 0.7013492584228516, loss G: 0.7103257775306702\n",
            "Epoch [42/100] Batch [700/782] Loss D: 0.6862937211990356, loss G: 0.7694345116615295\n",
            "Epoch [43/100] Batch [0/782] Loss D: 0.6929630041122437, loss G: 0.7770800590515137\n",
            "Epoch [43/100] Batch [100/782] Loss D: 0.655461311340332, loss G: 0.7972403764724731\n",
            "Epoch [43/100] Batch [200/782] Loss D: 0.7227639555931091, loss G: 0.7094312310218811\n",
            "Epoch [43/100] Batch [300/782] Loss D: 0.6998553276062012, loss G: 0.7630707025527954\n",
            "Epoch [43/100] Batch [400/782] Loss D: 0.6624234914779663, loss G: 0.7819774150848389\n",
            "Epoch [43/100] Batch [500/782] Loss D: 0.6642450094223022, loss G: 0.7300788760185242\n",
            "Epoch [43/100] Batch [600/782] Loss D: 0.6738108396530151, loss G: 0.6902772784233093\n",
            "Epoch [43/100] Batch [700/782] Loss D: 0.6886874437332153, loss G: 0.771453857421875\n",
            "Epoch [44/100] Batch [0/782] Loss D: 0.6629691123962402, loss G: 0.7584271430969238\n",
            "Epoch [44/100] Batch [100/782] Loss D: 0.7093868255615234, loss G: 0.7379601001739502\n",
            "Epoch [44/100] Batch [200/782] Loss D: 0.6791760921478271, loss G: 0.7222678661346436\n",
            "Epoch [44/100] Batch [300/782] Loss D: 0.6608585119247437, loss G: 0.7511088252067566\n",
            "Epoch [44/100] Batch [400/782] Loss D: 0.688385009765625, loss G: 0.7666002511978149\n",
            "Epoch [44/100] Batch [500/782] Loss D: 0.666803240776062, loss G: 0.7967031598091125\n",
            "Epoch [44/100] Batch [600/782] Loss D: 0.6687354445457458, loss G: 0.7281270027160645\n",
            "Epoch [44/100] Batch [700/782] Loss D: 0.6962787508964539, loss G: 0.732733964920044\n",
            "Epoch [45/100] Batch [0/782] Loss D: 0.6942441463470459, loss G: 0.7328740358352661\n",
            "Epoch [45/100] Batch [100/782] Loss D: 0.645557165145874, loss G: 0.759464681148529\n",
            "Epoch [45/100] Batch [200/782] Loss D: 0.6949323415756226, loss G: 0.7125561237335205\n",
            "Epoch [45/100] Batch [300/782] Loss D: 0.6869117021560669, loss G: 0.7195934057235718\n",
            "Epoch [45/100] Batch [400/782] Loss D: 0.7088778614997864, loss G: 0.7368496060371399\n",
            "Epoch [45/100] Batch [500/782] Loss D: 0.6700642704963684, loss G: 0.7476959228515625\n",
            "Epoch [45/100] Batch [600/782] Loss D: 0.6957648992538452, loss G: 0.7726343870162964\n",
            "Epoch [45/100] Batch [700/782] Loss D: 0.6558693051338196, loss G: 0.7461103796958923\n",
            "Epoch [46/100] Batch [0/782] Loss D: 0.6818517446517944, loss G: 0.7900596857070923\n",
            "Epoch [46/100] Batch [100/782] Loss D: 0.661407470703125, loss G: 0.7707366347312927\n",
            "Epoch [46/100] Batch [200/782] Loss D: 0.680677056312561, loss G: 0.7457991242408752\n",
            "Epoch [46/100] Batch [300/782] Loss D: 0.645697832107544, loss G: 0.7759987115859985\n",
            "Epoch [46/100] Batch [400/782] Loss D: 0.6686792969703674, loss G: 0.7610574960708618\n",
            "Epoch [46/100] Batch [500/782] Loss D: 0.6879786849021912, loss G: 0.7405095100402832\n",
            "Epoch [46/100] Batch [600/782] Loss D: 0.6674727201461792, loss G: 0.7393333911895752\n",
            "Epoch [46/100] Batch [700/782] Loss D: 0.7102124691009521, loss G: 0.6960700750350952\n",
            "Epoch [47/100] Batch [0/782] Loss D: 0.6865096688270569, loss G: 0.6935716867446899\n",
            "Epoch [47/100] Batch [100/782] Loss D: 0.6361972093582153, loss G: 0.761958122253418\n",
            "Epoch [47/100] Batch [200/782] Loss D: 0.7042770981788635, loss G: 0.75521320104599\n",
            "Epoch [47/100] Batch [300/782] Loss D: 0.6829837560653687, loss G: 0.7197507619857788\n",
            "Epoch [47/100] Batch [400/782] Loss D: 0.6501111388206482, loss G: 0.8094273805618286\n",
            "Epoch [47/100] Batch [500/782] Loss D: 0.6952674388885498, loss G: 0.7397265434265137\n",
            "Epoch [47/100] Batch [600/782] Loss D: 0.670694887638092, loss G: 0.7300230860710144\n",
            "Epoch [47/100] Batch [700/782] Loss D: 0.6637221574783325, loss G: 0.7471739053726196\n",
            "Epoch [48/100] Batch [0/782] Loss D: 0.6616179943084717, loss G: 0.7256622314453125\n",
            "Epoch [48/100] Batch [100/782] Loss D: 0.658889889717102, loss G: 0.7355338335037231\n",
            "Epoch [48/100] Batch [200/782] Loss D: 0.6581326723098755, loss G: 0.7798386812210083\n",
            "Epoch [48/100] Batch [300/782] Loss D: 0.688835084438324, loss G: 0.7389492392539978\n",
            "Epoch [48/100] Batch [400/782] Loss D: 0.6807658672332764, loss G: 0.7541793584823608\n",
            "Epoch [48/100] Batch [500/782] Loss D: 0.7118822336196899, loss G: 0.7342808246612549\n",
            "Epoch [48/100] Batch [600/782] Loss D: 0.6950543522834778, loss G: 0.7555210590362549\n",
            "Epoch [48/100] Batch [700/782] Loss D: 0.665047287940979, loss G: 0.7714170217514038\n",
            "Epoch [49/100] Batch [0/782] Loss D: 0.664130449295044, loss G: 0.8461830615997314\n",
            "Epoch [49/100] Batch [100/782] Loss D: 0.6926015615463257, loss G: 0.6837145686149597\n",
            "Epoch [49/100] Batch [200/782] Loss D: 0.6731301546096802, loss G: 0.7416849732398987\n",
            "Epoch [49/100] Batch [300/782] Loss D: 0.6826456785202026, loss G: 0.7249027490615845\n",
            "Epoch [49/100] Batch [400/782] Loss D: 0.7020325660705566, loss G: 0.7470762729644775\n",
            "Epoch [49/100] Batch [500/782] Loss D: 0.6618073582649231, loss G: 0.7973034381866455\n",
            "Epoch [49/100] Batch [600/782] Loss D: 0.6923692226409912, loss G: 0.7606828212738037\n",
            "Epoch [49/100] Batch [700/782] Loss D: 0.7036393284797668, loss G: 0.7490594387054443\n",
            "Epoch [50/100] Batch [0/782] Loss D: 0.6685421466827393, loss G: 0.7871538400650024\n",
            "Epoch [50/100] Batch [100/782] Loss D: 0.7028268575668335, loss G: 0.7359755039215088\n",
            "Epoch [50/100] Batch [200/782] Loss D: 0.672027587890625, loss G: 0.7439528703689575\n",
            "Epoch [50/100] Batch [300/782] Loss D: 0.6845957636833191, loss G: 0.7255743145942688\n",
            "Epoch [50/100] Batch [400/782] Loss D: 0.6407204866409302, loss G: 0.7724345922470093\n",
            "Epoch [50/100] Batch [500/782] Loss D: 0.6621757745742798, loss G: 0.7352937459945679\n",
            "Epoch [50/100] Batch [600/782] Loss D: 0.6566483378410339, loss G: 0.7622950673103333\n",
            "Epoch [50/100] Batch [700/782] Loss D: 0.6691811680793762, loss G: 0.7273686528205872\n",
            "Epoch [51/100] Batch [0/782] Loss D: 0.6631810665130615, loss G: 0.7252969741821289\n",
            "Epoch [51/100] Batch [100/782] Loss D: 0.6828160285949707, loss G: 0.7367613315582275\n",
            "Epoch [51/100] Batch [200/782] Loss D: 0.6789798736572266, loss G: 0.7752322554588318\n",
            "Epoch [51/100] Batch [300/782] Loss D: 0.676982045173645, loss G: 0.7466890811920166\n",
            "Epoch [51/100] Batch [400/782] Loss D: 0.7171643972396851, loss G: 0.7302142977714539\n",
            "Epoch [51/100] Batch [500/782] Loss D: 0.6387123465538025, loss G: 0.7423253655433655\n",
            "Epoch [51/100] Batch [600/782] Loss D: 0.6827413439750671, loss G: 0.6981755495071411\n",
            "Epoch [51/100] Batch [700/782] Loss D: 0.6682392954826355, loss G: 0.7391030788421631\n",
            "Epoch [52/100] Batch [0/782] Loss D: 0.6554351449012756, loss G: 0.7680237889289856\n",
            "Epoch [52/100] Batch [100/782] Loss D: 0.6705935001373291, loss G: 0.7495200037956238\n",
            "Epoch [52/100] Batch [200/782] Loss D: 0.6860799789428711, loss G: 0.7903407216072083\n",
            "Epoch [52/100] Batch [300/782] Loss D: 0.6364191174507141, loss G: 0.7501249313354492\n",
            "Epoch [52/100] Batch [400/782] Loss D: 0.6623280048370361, loss G: 0.7640306949615479\n",
            "Epoch [52/100] Batch [500/782] Loss D: 0.6616805791854858, loss G: 0.788322925567627\n",
            "Epoch [52/100] Batch [600/782] Loss D: 0.7036088705062866, loss G: 0.7299171686172485\n",
            "Epoch [52/100] Batch [700/782] Loss D: 0.6668090224266052, loss G: 0.7204015254974365\n",
            "Epoch [53/100] Batch [0/782] Loss D: 0.7250452041625977, loss G: 0.6545416116714478\n",
            "Epoch [53/100] Batch [100/782] Loss D: 0.661334753036499, loss G: 0.8075097799301147\n",
            "Epoch [53/100] Batch [200/782] Loss D: 0.6663353443145752, loss G: 0.7389885783195496\n",
            "Epoch [53/100] Batch [300/782] Loss D: 0.6783030033111572, loss G: 0.7477953433990479\n",
            "Epoch [53/100] Batch [400/782] Loss D: 0.6584255695343018, loss G: 0.7685284614562988\n",
            "Epoch [53/100] Batch [500/782] Loss D: 0.6603245735168457, loss G: 0.802578330039978\n",
            "Epoch [53/100] Batch [600/782] Loss D: 0.6690224409103394, loss G: 0.744199275970459\n",
            "Epoch [53/100] Batch [700/782] Loss D: 0.6617436408996582, loss G: 0.7174624800682068\n",
            "Epoch [54/100] Batch [0/782] Loss D: 0.6785330772399902, loss G: 0.7743251323699951\n",
            "Epoch [54/100] Batch [100/782] Loss D: 0.6473161578178406, loss G: 0.7669771313667297\n",
            "Epoch [54/100] Batch [200/782] Loss D: 0.6768161654472351, loss G: 0.7714265584945679\n",
            "Epoch [54/100] Batch [300/782] Loss D: 0.6570142507553101, loss G: 0.7878448963165283\n",
            "Epoch [54/100] Batch [400/782] Loss D: 0.6484765410423279, loss G: 0.7504263520240784\n",
            "Epoch [54/100] Batch [500/782] Loss D: 0.6593714952468872, loss G: 0.7600046396255493\n",
            "Epoch [54/100] Batch [600/782] Loss D: 0.6613065004348755, loss G: 0.7829233407974243\n",
            "Epoch [54/100] Batch [700/782] Loss D: 0.7088549733161926, loss G: 0.7137376666069031\n",
            "Epoch [55/100] Batch [0/782] Loss D: 0.673332691192627, loss G: 0.8285601139068604\n",
            "Epoch [55/100] Batch [100/782] Loss D: 0.6754138469696045, loss G: 0.7648211717605591\n",
            "Epoch [55/100] Batch [200/782] Loss D: 0.6493074297904968, loss G: 0.8516725301742554\n",
            "Epoch [55/100] Batch [300/782] Loss D: 0.6515568494796753, loss G: 0.7794145345687866\n",
            "Epoch [55/100] Batch [400/782] Loss D: 0.6575090289115906, loss G: 0.794241189956665\n",
            "Epoch [55/100] Batch [500/782] Loss D: 0.6997566223144531, loss G: 0.7894513010978699\n",
            "Epoch [55/100] Batch [600/782] Loss D: 0.6686050891876221, loss G: 0.7717134952545166\n",
            "Epoch [55/100] Batch [700/782] Loss D: 0.6585603952407837, loss G: 0.7672175168991089\n",
            "Epoch [56/100] Batch [0/782] Loss D: 0.6651135683059692, loss G: 0.7778950929641724\n",
            "Epoch [56/100] Batch [100/782] Loss D: 0.6649700403213501, loss G: 0.6995706558227539\n",
            "Epoch [56/100] Batch [200/782] Loss D: 0.6854866147041321, loss G: 0.8111812472343445\n",
            "Epoch [56/100] Batch [300/782] Loss D: 0.6694098711013794, loss G: 0.7584819793701172\n",
            "Epoch [56/100] Batch [400/782] Loss D: 0.6702401638031006, loss G: 0.75618976354599\n",
            "Epoch [56/100] Batch [500/782] Loss D: 0.6199030876159668, loss G: 0.8086835145950317\n",
            "Epoch [56/100] Batch [600/782] Loss D: 0.6916190385818481, loss G: 0.7365821599960327\n",
            "Epoch [56/100] Batch [700/782] Loss D: 0.6869890689849854, loss G: 0.7077172994613647\n",
            "Epoch [57/100] Batch [0/782] Loss D: 0.6804500222206116, loss G: 0.7411126494407654\n",
            "Epoch [57/100] Batch [100/782] Loss D: 0.6555851697921753, loss G: 0.8001146912574768\n",
            "Epoch [57/100] Batch [200/782] Loss D: 0.6564384698867798, loss G: 0.7640606760978699\n",
            "Epoch [57/100] Batch [300/782] Loss D: 0.6633877754211426, loss G: 0.7564883232116699\n",
            "Epoch [57/100] Batch [400/782] Loss D: 0.6701002717018127, loss G: 0.767744243144989\n",
            "Epoch [57/100] Batch [500/782] Loss D: 0.6566305160522461, loss G: 0.7512883543968201\n",
            "Epoch [57/100] Batch [600/782] Loss D: 0.6572072505950928, loss G: 0.7595413327217102\n",
            "Epoch [57/100] Batch [700/782] Loss D: 0.6545454859733582, loss G: 0.7704415321350098\n",
            "Epoch [58/100] Batch [0/782] Loss D: 0.6872370839118958, loss G: 0.745065450668335\n",
            "Epoch [58/100] Batch [100/782] Loss D: 0.6878845691680908, loss G: 0.7330012917518616\n",
            "Epoch [58/100] Batch [200/782] Loss D: 0.6602462530136108, loss G: 0.7834687829017639\n",
            "Epoch [58/100] Batch [300/782] Loss D: 0.653346836566925, loss G: 0.7769694328308105\n",
            "Epoch [58/100] Batch [400/782] Loss D: 0.6522010564804077, loss G: 0.7728806138038635\n",
            "Epoch [58/100] Batch [500/782] Loss D: 0.6793950796127319, loss G: 0.7835732698440552\n",
            "Epoch [58/100] Batch [600/782] Loss D: 0.6755232810974121, loss G: 0.7466847896575928\n",
            "Epoch [58/100] Batch [700/782] Loss D: 0.6739144921302795, loss G: 0.7644679546356201\n",
            "Epoch [59/100] Batch [0/782] Loss D: 0.6527057886123657, loss G: 0.7754021883010864\n",
            "Epoch [59/100] Batch [100/782] Loss D: 0.6364436745643616, loss G: 0.7807167768478394\n",
            "Epoch [59/100] Batch [200/782] Loss D: 0.6654777526855469, loss G: 0.8012685775756836\n",
            "Epoch [59/100] Batch [300/782] Loss D: 0.6780506372451782, loss G: 0.7473432421684265\n",
            "Epoch [59/100] Batch [400/782] Loss D: 0.6560890674591064, loss G: 0.7763450145721436\n",
            "Epoch [59/100] Batch [500/782] Loss D: 0.6463198065757751, loss G: 0.7140536904335022\n",
            "Epoch [59/100] Batch [600/782] Loss D: 0.673664391040802, loss G: 0.7267281413078308\n",
            "Epoch [59/100] Batch [700/782] Loss D: 0.6852669715881348, loss G: 0.7669464945793152\n",
            "Epoch [60/100] Batch [0/782] Loss D: 0.6453744173049927, loss G: 0.7496168613433838\n",
            "Epoch [60/100] Batch [100/782] Loss D: 0.6930196285247803, loss G: 0.7896941900253296\n",
            "Epoch [60/100] Batch [200/782] Loss D: 0.6689953804016113, loss G: 0.7353844046592712\n",
            "Epoch [60/100] Batch [300/782] Loss D: 0.6668229699134827, loss G: 0.7786509394645691\n",
            "Epoch [60/100] Batch [400/782] Loss D: 0.6566027402877808, loss G: 0.7539383769035339\n",
            "Epoch [60/100] Batch [500/782] Loss D: 0.6679078340530396, loss G: 0.8055124282836914\n",
            "Epoch [60/100] Batch [600/782] Loss D: 0.6632157564163208, loss G: 0.7589913606643677\n",
            "Epoch [60/100] Batch [700/782] Loss D: 0.649985134601593, loss G: 0.7266547679901123\n",
            "Epoch [61/100] Batch [0/782] Loss D: 0.6692677736282349, loss G: 0.7171173095703125\n",
            "Epoch [61/100] Batch [100/782] Loss D: 0.6662991046905518, loss G: 0.7656223773956299\n",
            "Epoch [61/100] Batch [200/782] Loss D: 0.6809283494949341, loss G: 0.781033456325531\n",
            "Epoch [61/100] Batch [300/782] Loss D: 0.621068000793457, loss G: 0.7812285423278809\n",
            "Epoch [61/100] Batch [400/782] Loss D: 0.6491948962211609, loss G: 0.7773208618164062\n",
            "Epoch [61/100] Batch [500/782] Loss D: 0.6686103343963623, loss G: 0.8161068558692932\n",
            "Epoch [61/100] Batch [600/782] Loss D: 0.6590517163276672, loss G: 0.7728207111358643\n",
            "Epoch [61/100] Batch [700/782] Loss D: 0.6900458335876465, loss G: 0.6960355639457703\n",
            "Epoch [62/100] Batch [0/782] Loss D: 0.6496891975402832, loss G: 0.760582447052002\n",
            "Epoch [62/100] Batch [100/782] Loss D: 0.6790865659713745, loss G: 0.782260537147522\n",
            "Epoch [62/100] Batch [200/782] Loss D: 0.6776390075683594, loss G: 0.7893551588058472\n",
            "Epoch [62/100] Batch [300/782] Loss D: 0.7095947265625, loss G: 0.7346979379653931\n",
            "Epoch [62/100] Batch [400/782] Loss D: 0.6594421863555908, loss G: 0.8203945159912109\n",
            "Epoch [62/100] Batch [500/782] Loss D: 0.6417875289916992, loss G: 0.7742208242416382\n",
            "Epoch [62/100] Batch [600/782] Loss D: 0.6552428007125854, loss G: 0.7306674718856812\n",
            "Epoch [62/100] Batch [700/782] Loss D: 0.6689300537109375, loss G: 0.7511513233184814\n",
            "Epoch [63/100] Batch [0/782] Loss D: 0.6693161725997925, loss G: 0.7963309288024902\n",
            "Epoch [63/100] Batch [100/782] Loss D: 0.6683441400527954, loss G: 0.75511634349823\n",
            "Epoch [63/100] Batch [200/782] Loss D: 0.659587025642395, loss G: 0.7746556997299194\n",
            "Epoch [63/100] Batch [300/782] Loss D: 0.6762142181396484, loss G: 0.7298406362533569\n",
            "Epoch [63/100] Batch [400/782] Loss D: 0.6418725252151489, loss G: 0.7748166918754578\n",
            "Epoch [63/100] Batch [500/782] Loss D: 0.6584472060203552, loss G: 0.7449082136154175\n",
            "Epoch [63/100] Batch [600/782] Loss D: 0.6815136671066284, loss G: 0.7541963458061218\n",
            "Epoch [63/100] Batch [700/782] Loss D: 0.6565920114517212, loss G: 0.7501342296600342\n",
            "Epoch [64/100] Batch [0/782] Loss D: 0.6470617651939392, loss G: 0.7525657415390015\n",
            "Epoch [64/100] Batch [100/782] Loss D: 0.6808648109436035, loss G: 0.7384781837463379\n",
            "Epoch [64/100] Batch [200/782] Loss D: 0.6529651880264282, loss G: 0.7673540115356445\n",
            "Epoch [64/100] Batch [300/782] Loss D: 0.666780948638916, loss G: 0.7342719435691833\n",
            "Epoch [64/100] Batch [400/782] Loss D: 0.6683552265167236, loss G: 0.7688551545143127\n",
            "Epoch [64/100] Batch [500/782] Loss D: 0.698085367679596, loss G: 0.7246395349502563\n",
            "Epoch [64/100] Batch [600/782] Loss D: 0.6357905864715576, loss G: 0.7816677093505859\n",
            "Epoch [64/100] Batch [700/782] Loss D: 0.6583251953125, loss G: 0.7700782418251038\n",
            "Epoch [65/100] Batch [0/782] Loss D: 0.6519955396652222, loss G: 0.7715063095092773\n",
            "Epoch [65/100] Batch [100/782] Loss D: 0.6585980653762817, loss G: 0.753401517868042\n",
            "Epoch [65/100] Batch [200/782] Loss D: 0.64067542552948, loss G: 0.7880768775939941\n",
            "Epoch [65/100] Batch [300/782] Loss D: 0.6636900901794434, loss G: 0.763248860836029\n",
            "Epoch [65/100] Batch [400/782] Loss D: 0.625529944896698, loss G: 0.7832922339439392\n",
            "Epoch [65/100] Batch [500/782] Loss D: 0.6808637380599976, loss G: 0.7485238313674927\n",
            "Epoch [65/100] Batch [600/782] Loss D: 0.6472028493881226, loss G: 0.77549809217453\n",
            "Epoch [65/100] Batch [700/782] Loss D: 0.6753692626953125, loss G: 0.7705754041671753\n",
            "Epoch [66/100] Batch [0/782] Loss D: 0.6593670845031738, loss G: 0.7856787443161011\n",
            "Epoch [66/100] Batch [100/782] Loss D: 0.6302887797355652, loss G: 0.8534233570098877\n",
            "Epoch [66/100] Batch [200/782] Loss D: 0.6604602336883545, loss G: 0.77724289894104\n",
            "Epoch [66/100] Batch [300/782] Loss D: 0.6334283351898193, loss G: 0.8340131044387817\n",
            "Epoch [66/100] Batch [400/782] Loss D: 0.6823340058326721, loss G: 0.729490339756012\n",
            "Epoch [66/100] Batch [500/782] Loss D: 0.6947197914123535, loss G: 0.8393042087554932\n",
            "Epoch [66/100] Batch [600/782] Loss D: 0.6530022621154785, loss G: 0.741759717464447\n",
            "Epoch [66/100] Batch [700/782] Loss D: 0.686211109161377, loss G: 0.7959209680557251\n",
            "Epoch [67/100] Batch [0/782] Loss D: 0.7117774486541748, loss G: 0.6733644008636475\n",
            "Epoch [67/100] Batch [100/782] Loss D: 0.6666728258132935, loss G: 0.7852749824523926\n",
            "Epoch [67/100] Batch [200/782] Loss D: 0.6719629764556885, loss G: 0.8253023028373718\n",
            "Epoch [67/100] Batch [300/782] Loss D: 0.6661653518676758, loss G: 0.7161237001419067\n",
            "Epoch [67/100] Batch [400/782] Loss D: 0.6638930439949036, loss G: 0.7959002256393433\n",
            "Epoch [67/100] Batch [500/782] Loss D: 0.6500840187072754, loss G: 0.8464058637619019\n",
            "Epoch [67/100] Batch [600/782] Loss D: 0.6210368871688843, loss G: 0.7942467927932739\n",
            "Epoch [67/100] Batch [700/782] Loss D: 0.6584872007369995, loss G: 0.7648813724517822\n",
            "Epoch [68/100] Batch [0/782] Loss D: 0.6510294675827026, loss G: 0.7765144109725952\n",
            "Epoch [68/100] Batch [100/782] Loss D: 0.6996567249298096, loss G: 0.7865593433380127\n",
            "Epoch [68/100] Batch [200/782] Loss D: 0.6755818724632263, loss G: 0.7436577081680298\n",
            "Epoch [68/100] Batch [300/782] Loss D: 0.6891705393791199, loss G: 0.7327626943588257\n",
            "Epoch [68/100] Batch [400/782] Loss D: 0.69761061668396, loss G: 0.8023697137832642\n",
            "Epoch [68/100] Batch [500/782] Loss D: 0.6823830008506775, loss G: 0.7948868274688721\n",
            "Epoch [68/100] Batch [600/782] Loss D: 0.6974631547927856, loss G: 0.7419218420982361\n",
            "Epoch [68/100] Batch [700/782] Loss D: 0.6263006329536438, loss G: 0.8107873797416687\n",
            "Epoch [69/100] Batch [0/782] Loss D: 0.6338114738464355, loss G: 0.8708933591842651\n",
            "Epoch [69/100] Batch [100/782] Loss D: 0.638363242149353, loss G: 0.8160116672515869\n",
            "Epoch [69/100] Batch [200/782] Loss D: 0.6898053288459778, loss G: 0.7444741725921631\n",
            "Epoch [69/100] Batch [300/782] Loss D: 0.6622391939163208, loss G: 0.74925696849823\n",
            "Epoch [69/100] Batch [400/782] Loss D: 0.6753417253494263, loss G: 0.8428172469139099\n",
            "Epoch [69/100] Batch [500/782] Loss D: 0.6596732139587402, loss G: 0.74406898021698\n",
            "Epoch [69/100] Batch [600/782] Loss D: 0.7033958435058594, loss G: 0.8112238645553589\n",
            "Epoch [69/100] Batch [700/782] Loss D: 0.6354576349258423, loss G: 0.7445076704025269\n",
            "Epoch [70/100] Batch [0/782] Loss D: 0.6679673790931702, loss G: 0.800356388092041\n",
            "Epoch [70/100] Batch [100/782] Loss D: 0.6811209917068481, loss G: 0.7335048317909241\n",
            "Epoch [70/100] Batch [200/782] Loss D: 0.6333810091018677, loss G: 0.7759719491004944\n",
            "Epoch [70/100] Batch [300/782] Loss D: 0.691251277923584, loss G: 0.798639178276062\n",
            "Epoch [70/100] Batch [400/782] Loss D: 0.6392496824264526, loss G: 0.8078956604003906\n",
            "Epoch [70/100] Batch [500/782] Loss D: 0.662559449672699, loss G: 0.7258665561676025\n",
            "Epoch [70/100] Batch [600/782] Loss D: 0.6999119520187378, loss G: 0.7558544874191284\n",
            "Epoch [70/100] Batch [700/782] Loss D: 0.6597983241081238, loss G: 0.7471184134483337\n",
            "Epoch [71/100] Batch [0/782] Loss D: 0.6359869241714478, loss G: 0.8358801603317261\n",
            "Epoch [71/100] Batch [100/782] Loss D: 0.6604559421539307, loss G: 0.7998183369636536\n",
            "Epoch [71/100] Batch [200/782] Loss D: 0.6291495561599731, loss G: 0.8717874884605408\n",
            "Epoch [71/100] Batch [300/782] Loss D: 0.6676208972930908, loss G: 0.7796387076377869\n",
            "Epoch [71/100] Batch [400/782] Loss D: 0.6388329267501831, loss G: 0.8577886819839478\n",
            "Epoch [71/100] Batch [500/782] Loss D: 0.690201997756958, loss G: 0.7558324337005615\n",
            "Epoch [71/100] Batch [600/782] Loss D: 0.6391158103942871, loss G: 0.7978014945983887\n",
            "Epoch [71/100] Batch [700/782] Loss D: 0.6587833166122437, loss G: 0.8156726956367493\n",
            "Epoch [72/100] Batch [0/782] Loss D: 0.6149282455444336, loss G: 0.7659556269645691\n",
            "Epoch [72/100] Batch [100/782] Loss D: 0.6439628005027771, loss G: 0.8228033781051636\n",
            "Epoch [72/100] Batch [200/782] Loss D: 0.6742810606956482, loss G: 0.8004248142242432\n",
            "Epoch [72/100] Batch [300/782] Loss D: 0.683276891708374, loss G: 0.7399194240570068\n",
            "Epoch [72/100] Batch [400/782] Loss D: 0.6243937015533447, loss G: 0.816771388053894\n",
            "Epoch [72/100] Batch [500/782] Loss D: 0.5992110967636108, loss G: 0.787879228591919\n",
            "Epoch [72/100] Batch [600/782] Loss D: 0.6631518006324768, loss G: 0.7961490154266357\n",
            "Epoch [72/100] Batch [700/782] Loss D: 0.6139469146728516, loss G: 0.8207147717475891\n",
            "Epoch [73/100] Batch [0/782] Loss D: 0.620445728302002, loss G: 0.8369423151016235\n",
            "Epoch [73/100] Batch [100/782] Loss D: 0.6431498527526855, loss G: 0.7829163074493408\n",
            "Epoch [73/100] Batch [200/782] Loss D: 0.6404340267181396, loss G: 0.7899031639099121\n",
            "Epoch [73/100] Batch [300/782] Loss D: 0.6679812073707581, loss G: 0.7663508057594299\n",
            "Epoch [73/100] Batch [400/782] Loss D: 0.6590088605880737, loss G: 0.8615460395812988\n",
            "Epoch [73/100] Batch [500/782] Loss D: 0.666354775428772, loss G: 0.7761636972427368\n",
            "Epoch [73/100] Batch [600/782] Loss D: 0.6667004823684692, loss G: 0.8090437054634094\n",
            "Epoch [73/100] Batch [700/782] Loss D: 0.6254410743713379, loss G: 0.7910875082015991\n",
            "Epoch [74/100] Batch [0/782] Loss D: 0.6643868684768677, loss G: 0.7515263557434082\n",
            "Epoch [74/100] Batch [100/782] Loss D: 0.6477364301681519, loss G: 0.7819607853889465\n",
            "Epoch [74/100] Batch [200/782] Loss D: 0.6259264945983887, loss G: 0.7805079817771912\n",
            "Epoch [74/100] Batch [300/782] Loss D: 0.6627360582351685, loss G: 0.8222376704216003\n",
            "Epoch [74/100] Batch [400/782] Loss D: 0.6286171674728394, loss G: 0.8509453535079956\n",
            "Epoch [74/100] Batch [500/782] Loss D: 0.689777135848999, loss G: 0.8312506079673767\n",
            "Epoch [74/100] Batch [600/782] Loss D: 0.6396902799606323, loss G: 0.7588244676589966\n",
            "Epoch [74/100] Batch [700/782] Loss D: 0.6693977117538452, loss G: 0.7824009656906128\n",
            "Epoch [75/100] Batch [0/782] Loss D: 0.6499592065811157, loss G: 0.7651456594467163\n",
            "Epoch [75/100] Batch [100/782] Loss D: 0.6381477117538452, loss G: 0.8226984739303589\n",
            "Epoch [75/100] Batch [200/782] Loss D: 0.6238973736763, loss G: 0.8179612159729004\n",
            "Epoch [75/100] Batch [300/782] Loss D: 0.6490633487701416, loss G: 0.8203507661819458\n",
            "Epoch [75/100] Batch [400/782] Loss D: 0.6419238448143005, loss G: 0.8135695457458496\n",
            "Epoch [75/100] Batch [500/782] Loss D: 0.6458794474601746, loss G: 0.7699910998344421\n",
            "Epoch [75/100] Batch [600/782] Loss D: 0.6447011828422546, loss G: 0.7726808786392212\n",
            "Epoch [75/100] Batch [700/782] Loss D: 0.6664491891860962, loss G: 0.7911357879638672\n",
            "Epoch [76/100] Batch [0/782] Loss D: 0.6618162393569946, loss G: 0.789372444152832\n",
            "Epoch [76/100] Batch [100/782] Loss D: 0.7130720615386963, loss G: 0.7272128462791443\n",
            "Epoch [76/100] Batch [200/782] Loss D: 0.6180406808853149, loss G: 0.7789210677146912\n",
            "Epoch [76/100] Batch [300/782] Loss D: 0.6263445615768433, loss G: 0.8473294377326965\n",
            "Epoch [76/100] Batch [400/782] Loss D: 0.655540406703949, loss G: 0.8916516304016113\n",
            "Epoch [76/100] Batch [500/782] Loss D: 0.6699150800704956, loss G: 0.8093708753585815\n",
            "Epoch [76/100] Batch [600/782] Loss D: 0.6966365575790405, loss G: 0.7373331785202026\n",
            "Epoch [76/100] Batch [700/782] Loss D: 0.6447717547416687, loss G: 0.7680951356887817\n",
            "Epoch [77/100] Batch [0/782] Loss D: 0.6852527856826782, loss G: 0.792570173740387\n",
            "Epoch [77/100] Batch [100/782] Loss D: 0.6471894979476929, loss G: 0.7789250612258911\n",
            "Epoch [77/100] Batch [200/782] Loss D: 0.6252578496932983, loss G: 0.8392785787582397\n",
            "Epoch [77/100] Batch [300/782] Loss D: 0.6401304006576538, loss G: 0.7847863435745239\n",
            "Epoch [77/100] Batch [400/782] Loss D: 0.6691172122955322, loss G: 0.7985003590583801\n",
            "Epoch [77/100] Batch [500/782] Loss D: 0.6359769105911255, loss G: 0.8131430745124817\n",
            "Epoch [77/100] Batch [600/782] Loss D: 0.6904869675636292, loss G: 0.8045450448989868\n",
            "Epoch [77/100] Batch [700/782] Loss D: 0.6641503572463989, loss G: 0.8207210898399353\n",
            "Epoch [78/100] Batch [0/782] Loss D: 0.6957707405090332, loss G: 0.7952850461006165\n",
            "Epoch [78/100] Batch [100/782] Loss D: 0.6499022245407104, loss G: 0.7782504558563232\n",
            "Epoch [78/100] Batch [200/782] Loss D: 0.6585979461669922, loss G: 0.8045727610588074\n",
            "Epoch [78/100] Batch [300/782] Loss D: 0.6235332489013672, loss G: 0.8554672002792358\n",
            "Epoch [78/100] Batch [400/782] Loss D: 0.6696814298629761, loss G: 0.7884973287582397\n",
            "Epoch [78/100] Batch [500/782] Loss D: 0.6543194055557251, loss G: 0.7977429032325745\n",
            "Epoch [78/100] Batch [600/782] Loss D: 0.6407953500747681, loss G: 0.7796065807342529\n",
            "Epoch [78/100] Batch [700/782] Loss D: 0.60563063621521, loss G: 0.8385642170906067\n",
            "Epoch [79/100] Batch [0/782] Loss D: 0.6168027520179749, loss G: 0.7947390079498291\n",
            "Epoch [79/100] Batch [100/782] Loss D: 0.6327963471412659, loss G: 0.8196442127227783\n",
            "Epoch [79/100] Batch [200/782] Loss D: 0.6551964282989502, loss G: 0.8128296136856079\n",
            "Epoch [79/100] Batch [300/782] Loss D: 0.6882201433181763, loss G: 0.8081896901130676\n",
            "Epoch [79/100] Batch [400/782] Loss D: 0.6870784163475037, loss G: 0.8039940595626831\n",
            "Epoch [79/100] Batch [500/782] Loss D: 0.655235767364502, loss G: 0.7276538014411926\n",
            "Epoch [79/100] Batch [600/782] Loss D: 0.678473711013794, loss G: 0.7915316820144653\n",
            "Epoch [79/100] Batch [700/782] Loss D: 0.6401194334030151, loss G: 0.8094823956489563\n",
            "Epoch [80/100] Batch [0/782] Loss D: 0.6743975877761841, loss G: 0.7596101760864258\n",
            "Epoch [80/100] Batch [100/782] Loss D: 0.6828332543373108, loss G: 0.7715656757354736\n",
            "Epoch [80/100] Batch [200/782] Loss D: 0.6780796647071838, loss G: 0.7826975584030151\n",
            "Epoch [80/100] Batch [300/782] Loss D: 0.6920729279518127, loss G: 0.7992442846298218\n",
            "Epoch [80/100] Batch [400/782] Loss D: 0.6707031726837158, loss G: 0.7356452941894531\n",
            "Epoch [80/100] Batch [500/782] Loss D: 0.6491807103157043, loss G: 0.8329654932022095\n",
            "Epoch [80/100] Batch [600/782] Loss D: 0.6216856241226196, loss G: 0.7738595604896545\n",
            "Epoch [80/100] Batch [700/782] Loss D: 0.6355482935905457, loss G: 0.782112717628479\n",
            "Epoch [81/100] Batch [0/782] Loss D: 0.6740673780441284, loss G: 0.6806079745292664\n",
            "Epoch [81/100] Batch [100/782] Loss D: 0.653767466545105, loss G: 0.788779616355896\n",
            "Epoch [81/100] Batch [200/782] Loss D: 0.6365149617195129, loss G: 0.8113225698471069\n",
            "Epoch [81/100] Batch [300/782] Loss D: 0.6236966252326965, loss G: 0.8031966686248779\n",
            "Epoch [81/100] Batch [400/782] Loss D: 0.6494219303131104, loss G: 0.8441974520683289\n",
            "Epoch [81/100] Batch [500/782] Loss D: 0.6899845600128174, loss G: 0.7722997665405273\n",
            "Epoch [81/100] Batch [600/782] Loss D: 0.6809107661247253, loss G: 0.7785048484802246\n",
            "Epoch [81/100] Batch [700/782] Loss D: 0.6753828525543213, loss G: 0.7480946779251099\n",
            "Epoch [82/100] Batch [0/782] Loss D: 0.6758168935775757, loss G: 0.7576617002487183\n",
            "Epoch [82/100] Batch [100/782] Loss D: 0.6270666122436523, loss G: 0.8022464513778687\n",
            "Epoch [82/100] Batch [200/782] Loss D: 0.6797876358032227, loss G: 0.7787421941757202\n",
            "Epoch [82/100] Batch [300/782] Loss D: 0.6657655239105225, loss G: 0.8403582572937012\n",
            "Epoch [82/100] Batch [400/782] Loss D: 0.6834895610809326, loss G: 0.8063031435012817\n",
            "Epoch [82/100] Batch [500/782] Loss D: 0.6679396033287048, loss G: 0.8018052577972412\n",
            "Epoch [82/100] Batch [600/782] Loss D: 0.6358481645584106, loss G: 0.8406944274902344\n",
            "Epoch [82/100] Batch [700/782] Loss D: 0.6284517645835876, loss G: 0.8417143821716309\n",
            "Epoch [83/100] Batch [0/782] Loss D: 0.6659928560256958, loss G: 0.769029974937439\n",
            "Epoch [83/100] Batch [100/782] Loss D: 0.6402999758720398, loss G: 0.8199858665466309\n",
            "Epoch [83/100] Batch [200/782] Loss D: 0.6941297650337219, loss G: 0.7846532464027405\n",
            "Epoch [83/100] Batch [300/782] Loss D: 0.6299770474433899, loss G: 0.8494579195976257\n",
            "Epoch [83/100] Batch [400/782] Loss D: 0.6601370573043823, loss G: 0.7854720950126648\n",
            "Epoch [83/100] Batch [500/782] Loss D: 0.6777567267417908, loss G: 0.8145325779914856\n",
            "Epoch [83/100] Batch [600/782] Loss D: 0.6649615168571472, loss G: 0.8217611312866211\n",
            "Epoch [83/100] Batch [700/782] Loss D: 0.6356316804885864, loss G: 0.7880266904830933\n",
            "Epoch [84/100] Batch [0/782] Loss D: 0.6709737777709961, loss G: 0.7734782099723816\n",
            "Epoch [84/100] Batch [100/782] Loss D: 0.6893086433410645, loss G: 0.7104922533035278\n",
            "Epoch [84/100] Batch [200/782] Loss D: 0.6694466471672058, loss G: 0.7038986086845398\n",
            "Epoch [84/100] Batch [300/782] Loss D: 0.6708671450614929, loss G: 0.7758201360702515\n",
            "Epoch [84/100] Batch [400/782] Loss D: 0.6363149881362915, loss G: 0.8002413511276245\n",
            "Epoch [84/100] Batch [500/782] Loss D: 0.6566447019577026, loss G: 0.7233057022094727\n",
            "Epoch [84/100] Batch [600/782] Loss D: 0.6560888886451721, loss G: 0.7941184043884277\n",
            "Epoch [84/100] Batch [700/782] Loss D: 0.6283965110778809, loss G: 0.7555704116821289\n",
            "Epoch [85/100] Batch [0/782] Loss D: 0.6877332925796509, loss G: 0.7216938734054565\n",
            "Epoch [85/100] Batch [100/782] Loss D: 0.6810061931610107, loss G: 0.8121464252471924\n",
            "Epoch [85/100] Batch [200/782] Loss D: 0.630447506904602, loss G: 0.8402042388916016\n",
            "Epoch [85/100] Batch [300/782] Loss D: 0.6715021133422852, loss G: 0.7458659410476685\n",
            "Epoch [85/100] Batch [400/782] Loss D: 0.678646981716156, loss G: 0.8115770816802979\n",
            "Epoch [85/100] Batch [500/782] Loss D: 0.6805298328399658, loss G: 0.7797791957855225\n",
            "Epoch [85/100] Batch [600/782] Loss D: 0.646003782749176, loss G: 0.8519139289855957\n",
            "Epoch [85/100] Batch [700/782] Loss D: 0.6598258018493652, loss G: 0.7988477945327759\n",
            "Epoch [86/100] Batch [0/782] Loss D: 0.6446095705032349, loss G: 0.7909075021743774\n",
            "Epoch [86/100] Batch [100/782] Loss D: 0.6662966012954712, loss G: 0.7518144845962524\n",
            "Epoch [86/100] Batch [200/782] Loss D: 0.6279287338256836, loss G: 0.8344690203666687\n",
            "Epoch [86/100] Batch [300/782] Loss D: 0.651046872138977, loss G: 0.8608021140098572\n",
            "Epoch [86/100] Batch [400/782] Loss D: 0.6799862384796143, loss G: 0.7616817951202393\n",
            "Epoch [86/100] Batch [500/782] Loss D: 0.633831799030304, loss G: 0.8132243156433105\n",
            "Epoch [86/100] Batch [600/782] Loss D: 0.6303411722183228, loss G: 0.7878017425537109\n",
            "Epoch [86/100] Batch [700/782] Loss D: 0.6772159337997437, loss G: 0.8225515484809875\n",
            "Epoch [87/100] Batch [0/782] Loss D: 0.6497958898544312, loss G: 0.843622088432312\n",
            "Epoch [87/100] Batch [100/782] Loss D: 0.6499028205871582, loss G: 0.7473547458648682\n",
            "Epoch [87/100] Batch [200/782] Loss D: 0.6531082391738892, loss G: 0.7934030294418335\n",
            "Epoch [87/100] Batch [300/782] Loss D: 0.6263092756271362, loss G: 0.7543145418167114\n",
            "Epoch [87/100] Batch [400/782] Loss D: 0.6328116655349731, loss G: 0.7971310615539551\n",
            "Epoch [87/100] Batch [500/782] Loss D: 0.6457700133323669, loss G: 0.8078140020370483\n",
            "Epoch [87/100] Batch [600/782] Loss D: 0.5985316038131714, loss G: 0.8629881143569946\n",
            "Epoch [87/100] Batch [700/782] Loss D: 0.6809749007225037, loss G: 0.8444951772689819\n",
            "Epoch [88/100] Batch [0/782] Loss D: 0.6367076635360718, loss G: 0.8327702283859253\n",
            "Epoch [88/100] Batch [100/782] Loss D: 0.6259070634841919, loss G: 0.7999691963195801\n",
            "Epoch [88/100] Batch [200/782] Loss D: 0.7186596393585205, loss G: 0.7455180883407593\n",
            "Epoch [88/100] Batch [300/782] Loss D: 0.6547037363052368, loss G: 0.8332610726356506\n",
            "Epoch [88/100] Batch [400/782] Loss D: 0.6887525320053101, loss G: 0.7551059722900391\n",
            "Epoch [88/100] Batch [500/782] Loss D: 0.7002679109573364, loss G: 0.7833177447319031\n",
            "Epoch [88/100] Batch [600/782] Loss D: 0.6748138666152954, loss G: 0.8037353754043579\n",
            "Epoch [88/100] Batch [700/782] Loss D: 0.6491309404373169, loss G: 0.7844876646995544\n",
            "Epoch [89/100] Batch [0/782] Loss D: 0.6648715138435364, loss G: 0.7787190079689026\n",
            "Epoch [89/100] Batch [100/782] Loss D: 0.6487448215484619, loss G: 0.7954840064048767\n",
            "Epoch [89/100] Batch [200/782] Loss D: 0.6438192129135132, loss G: 0.8392882347106934\n",
            "Epoch [89/100] Batch [300/782] Loss D: 0.626549482345581, loss G: 0.8490986824035645\n",
            "Epoch [89/100] Batch [400/782] Loss D: 0.6312939524650574, loss G: 0.8047717809677124\n",
            "Epoch [89/100] Batch [500/782] Loss D: 0.6300946474075317, loss G: 0.8302391767501831\n",
            "Epoch [89/100] Batch [600/782] Loss D: 0.6441909670829773, loss G: 0.7979681491851807\n",
            "Epoch [89/100] Batch [700/782] Loss D: 0.6591092348098755, loss G: 0.7995666265487671\n",
            "Epoch [90/100] Batch [0/782] Loss D: 0.6193206310272217, loss G: 0.7702038884162903\n",
            "Epoch [90/100] Batch [100/782] Loss D: 0.6297240853309631, loss G: 0.8044190406799316\n",
            "Epoch [90/100] Batch [200/782] Loss D: 0.6629051566123962, loss G: 0.8418065309524536\n",
            "Epoch [90/100] Batch [300/782] Loss D: 0.6736888885498047, loss G: 0.8238778114318848\n",
            "Epoch [90/100] Batch [400/782] Loss D: 0.6736152172088623, loss G: 0.7464061975479126\n",
            "Epoch [90/100] Batch [500/782] Loss D: 0.6954282522201538, loss G: 0.8243340253829956\n",
            "Epoch [90/100] Batch [600/782] Loss D: 0.6197816133499146, loss G: 0.7585520148277283\n",
            "Epoch [90/100] Batch [700/782] Loss D: 0.6530488729476929, loss G: 0.7511983513832092\n",
            "Epoch [91/100] Batch [0/782] Loss D: 0.6407738327980042, loss G: 0.8456076979637146\n",
            "Epoch [91/100] Batch [100/782] Loss D: 0.6577373743057251, loss G: 0.8431852459907532\n",
            "Epoch [91/100] Batch [200/782] Loss D: 0.6390236020088196, loss G: 0.7904963493347168\n",
            "Epoch [91/100] Batch [300/782] Loss D: 0.6262811422348022, loss G: 0.8065979480743408\n",
            "Epoch [91/100] Batch [400/782] Loss D: 0.6613484025001526, loss G: 0.7936238050460815\n",
            "Epoch [91/100] Batch [500/782] Loss D: 0.6497406959533691, loss G: 0.8472179174423218\n",
            "Epoch [91/100] Batch [600/782] Loss D: 0.6417248249053955, loss G: 0.8298240303993225\n",
            "Epoch [91/100] Batch [700/782] Loss D: 0.6780077219009399, loss G: 0.8055111169815063\n",
            "Epoch [92/100] Batch [0/782] Loss D: 0.6446425914764404, loss G: 0.7990466356277466\n",
            "Epoch [92/100] Batch [100/782] Loss D: 0.6517366766929626, loss G: 0.839903712272644\n",
            "Epoch [92/100] Batch [200/782] Loss D: 0.6585638523101807, loss G: 0.7777193188667297\n",
            "Epoch [92/100] Batch [300/782] Loss D: 0.6952522993087769, loss G: 0.7526912689208984\n",
            "Epoch [92/100] Batch [400/782] Loss D: 0.6390761137008667, loss G: 0.7960106134414673\n",
            "Epoch [92/100] Batch [500/782] Loss D: 0.6887521743774414, loss G: 0.7613190412521362\n",
            "Epoch [92/100] Batch [600/782] Loss D: 0.6456022262573242, loss G: 0.7898715138435364\n",
            "Epoch [92/100] Batch [700/782] Loss D: 0.6510627865791321, loss G: 0.8392970561981201\n",
            "Epoch [93/100] Batch [0/782] Loss D: 0.6586226224899292, loss G: 0.8008743524551392\n",
            "Epoch [93/100] Batch [100/782] Loss D: 0.7108473777770996, loss G: 0.8219456076622009\n",
            "Epoch [93/100] Batch [200/782] Loss D: 0.642261266708374, loss G: 0.7789825797080994\n",
            "Epoch [93/100] Batch [300/782] Loss D: 0.6122834086418152, loss G: 0.7936991453170776\n",
            "Epoch [93/100] Batch [400/782] Loss D: 0.6569321155548096, loss G: 0.7858793139457703\n",
            "Epoch [93/100] Batch [500/782] Loss D: 0.6736117601394653, loss G: 0.7743755578994751\n",
            "Epoch [93/100] Batch [600/782] Loss D: 0.6245541572570801, loss G: 0.8991732001304626\n",
            "Epoch [93/100] Batch [700/782] Loss D: 0.6640165448188782, loss G: 0.8425261974334717\n",
            "Epoch [94/100] Batch [0/782] Loss D: 0.6748851537704468, loss G: 0.705454409122467\n",
            "Epoch [94/100] Batch [100/782] Loss D: 0.6567920446395874, loss G: 0.8309526443481445\n",
            "Epoch [94/100] Batch [200/782] Loss D: 0.658900260925293, loss G: 0.7913448810577393\n",
            "Epoch [94/100] Batch [300/782] Loss D: 0.6592733860015869, loss G: 0.7746204137802124\n",
            "Epoch [94/100] Batch [400/782] Loss D: 0.6842641234397888, loss G: 0.75925213098526\n",
            "Epoch [94/100] Batch [500/782] Loss D: 0.6382670402526855, loss G: 0.8268017172813416\n",
            "Epoch [94/100] Batch [600/782] Loss D: 0.650629997253418, loss G: 0.8400838375091553\n",
            "Epoch [94/100] Batch [700/782] Loss D: 0.6641486883163452, loss G: 0.8218549489974976\n",
            "Epoch [95/100] Batch [0/782] Loss D: 0.6289189457893372, loss G: 0.8220118284225464\n",
            "Epoch [95/100] Batch [100/782] Loss D: 0.6281360983848572, loss G: 0.8690354228019714\n",
            "Epoch [95/100] Batch [200/782] Loss D: 0.6801988482475281, loss G: 0.864355206489563\n",
            "Epoch [95/100] Batch [300/782] Loss D: 0.6748545169830322, loss G: 0.7176929712295532\n",
            "Epoch [95/100] Batch [400/782] Loss D: 0.6575896739959717, loss G: 0.8417456746101379\n",
            "Epoch [95/100] Batch [500/782] Loss D: 0.6720783710479736, loss G: 0.7557438611984253\n",
            "Epoch [95/100] Batch [600/782] Loss D: 0.6576495170593262, loss G: 0.8096118569374084\n",
            "Epoch [95/100] Batch [700/782] Loss D: 0.7016026377677917, loss G: 0.7681724429130554\n",
            "Epoch [96/100] Batch [0/782] Loss D: 0.6621172428131104, loss G: 0.8166056275367737\n",
            "Epoch [96/100] Batch [100/782] Loss D: 0.6726917028427124, loss G: 0.7730733156204224\n",
            "Epoch [96/100] Batch [200/782] Loss D: 0.6696491241455078, loss G: 0.8661465644836426\n",
            "Epoch [96/100] Batch [300/782] Loss D: 0.6390140056610107, loss G: 0.839033842086792\n",
            "Epoch [96/100] Batch [400/782] Loss D: 0.6300768852233887, loss G: 0.896642804145813\n",
            "Epoch [96/100] Batch [500/782] Loss D: 0.6191643476486206, loss G: 0.8248107433319092\n",
            "Epoch [96/100] Batch [600/782] Loss D: 0.68473219871521, loss G: 0.7979300022125244\n",
            "Epoch [96/100] Batch [700/782] Loss D: 0.6496863961219788, loss G: 0.8307766914367676\n",
            "Epoch [97/100] Batch [0/782] Loss D: 0.640902042388916, loss G: 0.8132598400115967\n",
            "Epoch [97/100] Batch [100/782] Loss D: 0.6397819519042969, loss G: 0.8152055144309998\n",
            "Epoch [97/100] Batch [200/782] Loss D: 0.6415272355079651, loss G: 0.8137637972831726\n",
            "Epoch [97/100] Batch [300/782] Loss D: 0.6183300018310547, loss G: 0.8467357158660889\n",
            "Epoch [97/100] Batch [400/782] Loss D: 0.6771068572998047, loss G: 0.8355617523193359\n",
            "Epoch [97/100] Batch [500/782] Loss D: 0.6398038864135742, loss G: 0.8250578045845032\n",
            "Epoch [97/100] Batch [600/782] Loss D: 0.5960818529129028, loss G: 0.7949724793434143\n",
            "Epoch [97/100] Batch [700/782] Loss D: 0.6701308488845825, loss G: 0.7941932678222656\n",
            "Epoch [98/100] Batch [0/782] Loss D: 0.6527059674263, loss G: 0.819603443145752\n",
            "Epoch [98/100] Batch [100/782] Loss D: 0.6702691316604614, loss G: 0.7738410234451294\n",
            "Epoch [98/100] Batch [200/782] Loss D: 0.6425628662109375, loss G: 0.8213443756103516\n",
            "Epoch [98/100] Batch [300/782] Loss D: 0.6001255512237549, loss G: 0.7917409539222717\n",
            "Epoch [98/100] Batch [400/782] Loss D: 0.6336820125579834, loss G: 0.7736272215843201\n",
            "Epoch [98/100] Batch [500/782] Loss D: 0.6475516557693481, loss G: 0.7502790689468384\n",
            "Epoch [98/100] Batch [600/782] Loss D: 0.6539031267166138, loss G: 0.7597429752349854\n",
            "Epoch [98/100] Batch [700/782] Loss D: 0.6465967297554016, loss G: 0.8323663473129272\n",
            "Epoch [99/100] Batch [0/782] Loss D: 0.624505341053009, loss G: 0.8499590754508972\n",
            "Epoch [99/100] Batch [100/782] Loss D: 0.6566872596740723, loss G: 0.7730965614318848\n",
            "Epoch [99/100] Batch [200/782] Loss D: 0.6569716930389404, loss G: 0.8337289094924927\n",
            "Epoch [99/100] Batch [300/782] Loss D: 0.6898292303085327, loss G: 0.7818427681922913\n",
            "Epoch [99/100] Batch [400/782] Loss D: 0.6248177289962769, loss G: 0.8471839427947998\n",
            "Epoch [99/100] Batch [500/782] Loss D: 0.7048963308334351, loss G: 0.8057813048362732\n",
            "Epoch [99/100] Batch [600/782] Loss D: 0.6627724170684814, loss G: 0.7700095176696777\n",
            "Epoch [99/100] Batch [700/782] Loss D: 0.6279792785644531, loss G: 0.8764482140541077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[3][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X50bpgXloXXh",
        "outputId": "29186853-ba14-4720-d7c2-f20ef5a499e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_save_images(generator, num_images=10):\n",
        "    z = torch.randn(num_images, latent_dim, device=device)\n",
        "    labels = torch.arange(num_images, device=device)\n",
        "    gen_imgs = generator(z, labels).detach().cpu()\n",
        "    fig, axs = plt.subplots(1, num_images, figsize=(15, 15))\n",
        "    for i, img in enumerate(gen_imgs):\n",
        "        img = (img+1)/2\n",
        "        axs[i].imshow(img.squeeze().permute(1, 2, 0))\n",
        "        axs[i].axis('off')\n",
        "        axs[i].set_title(f\"Label: {labels[i].item()}\")\n",
        "    plt.show()\n",
        "\n",
        "# Générer des exemples\n",
        "generate_and_save_images(generator)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "id": "qx_U4i3ZoPGb",
        "outputId": "26172c7a-65db-4e90-f113-3f0eb0e32477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1500 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim, num_classes, img_size, channels):\n",
        "        super(Generator, self).__init__()\n",
        "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
        "        self.init_size = img_size // 4  # Réduire la taille de l'image progressivement\n",
        "        self.l1 = nn.Sequential(\n",
        "            nn.Linear(latent_dim + num_classes, 256 * self.init_size ** 2)  # Plus de filtres pour plus de détails\n",
        "        )\n",
        "\n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            nn.BatchNorm2d(256),  # Augmenter le nombre de canaux\n",
        "            nn.Upsample(scale_factor=2),  # Augmentation progressive de la taille\n",
        "            nn.Conv2d(256, 256, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(256, 128, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Upsample(scale_factor=2),  # Pour des images de plus haute résolution\n",
        "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, channels, 3, stride=1, padding=1),\n",
        "            nn.Tanh()  # Contrainte pour la plage de pixel entre -1 et 1\n",
        "        )\n",
        "\n",
        "    def forward(self, noise, labels):\n",
        "        # Passer les labels dans l'Embedding, puis les ajuster en taille\n",
        "        label_embeds = self.label_emb(labels)\n",
        "\n",
        "        # Concatenate noise et label_embeds, il faut les aplatir avant la concaténation\n",
        "        gen_input = torch.cat((noise, label_embeds), -1)  # Ici, on concatène le bruit et les labels dans la dimension -1\n",
        "\n",
        "        # Passage à travers la couche linéaire\n",
        "        out = self.l1(gen_input)\n",
        "\n",
        "        # Reshape la sortie pour qu'elle corresponde aux dimensions nécessaires pour la convolution\n",
        "        out = out.view(out.size(0), 256, self.init_size, self.init_size)  # Reshape pour passer à la couche suivante\n",
        "        img = self.conv_blocks(out)  # Passage dans les convolutions pour générer l'image\n",
        "\n",
        "        return img\n"
      ],
      "metadata": {
        "id": "WfvJKxoUo6Uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n"
      ],
      "metadata": {
        "id": "Aw4TJDxU_9sO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 100  # Dimension du vecteur latent\n",
        "num_classes = 40  # Nombre d'attributs dans CelebA\n",
        "img_size = 128  # Taille de l'image d'entrée\n",
        "channels = 3  # Nombre de canaux (images RGB)\n",
        "\n",
        "# Transformations à appliquer sur les images\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(img_size),  # Redimensionner les images\n",
        "    transforms.CenterCrop(img_size),  # Recadrer l'image au format img_size x img_size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalisation entre -1 et 1\n",
        "])\n",
        "train_dataset = datasets.CelebA(root='./data', split='train', transform=transform, download=True)\n",
        "\n",
        "# DataLoader\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHIJtqjBwZgD",
        "outputId": "d1d5a49a-b568-4b32-8f22-fc61e4564a85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=0B7EVK8r0v71pZjFTYXZWM3FlRnM\n",
            "From (redirected): https://drive.usercontent.google.com/download?id=0B7EVK8r0v71pZjFTYXZWM3FlRnM&confirm=t&uuid=c9003078-b7ae-43d4-893a-bab4858789c5\n",
            "To: /content/data/celeba/img_align_celeba.zip\n",
            "100%|██████████| 1.44G/1.44G [00:12<00:00, 117MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=0B7EVK8r0v71pblRyaVFSWGxPY0U\n",
            "To: /content/data/celeba/list_attr_celeba.txt\n",
            "100%|██████████| 26.7M/26.7M [00:00<00:00, 79.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1_ee_0u7vcNLOfNLegJRHmolfH5ICW-XS\n",
            "To: /content/data/celeba/identity_CelebA.txt\n",
            "100%|██████████| 3.42M/3.42M [00:00<00:00, 126MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=0B7EVK8r0v71pbThiMVRxWXZ4dU0\n",
            "To: /content/data/celeba/list_bbox_celeba.txt\n",
            "100%|██████████| 6.08M/6.08M [00:00<00:00, 191MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=0B7EVK8r0v71pd0FJY3Blby1HUTQ\n",
            "To: /content/data/celeba/list_landmarks_align_celeba.txt\n",
            "100%|██████████| 12.2M/12.2M [00:00<00:00, 110MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=0B7EVK8r0v71pY0NSMzRuSXJEVkk\n",
            "To: /content/data/celeba/list_eval_partition.txt\n",
            "100%|██████████| 2.84M/2.84M [00:00<00:00, 60.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "KKlYHjM4BmaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim, num_classes, img_size, channels):\n",
        "        super(Generator, self).__init__()\n",
        "        self.label_emb = nn.Embedding(num_classes, num_classes)  # Embedding des labels\n",
        "        self.init_size = img_size // 4  # Changed from img_size // 4 to img_size // 8\n",
        "        self.l1 = nn.Sequential(\n",
        "            nn.Linear(latent_dim + num_classes, 256 * self.init_size ** 2)  # Dimension après concaténation\n",
        "        )\n",
        "\n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            nn.BatchNorm2d(256),  # Augmenter le nombre de canaux\n",
        "            nn.Upsample(scale_factor=2),  # Augmentation progressive de la taille\n",
        "            nn.Conv2d(256, 256, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(256, 128, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(128, 64, 3, stride=1, padding=1), #removed nn.Upsample(scale_factor=2)\n",
        "            nn.BatchNorm2d(64, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, channels, 3, stride=1, padding=1),\n",
        "            nn.Tanh()  # Contrainte pour la plage de pixel entre -1 et 1\n",
        "        )\n",
        "\n",
        "    def forward(self, noise, labels):\n",
        "        # Convertir les labels one-hot en indices\n",
        "\n",
        "        # Passer les labels dans l'Embedding\n",
        "        label_embeds = torch.matmul(labels.float(), self.label_emb.weight)  # (batch_size, num_classes)\n",
        "\n",
        "        # Concatenate le bruit et les labels\n",
        "        gen_input = torch.cat((noise, label_embeds), -1)  # Concaténation des deux dans la dernière dimension\n",
        "\n",
        "        # Passage à travers la couche linéaire\n",
        "        out = self.l1(gen_input)\n",
        "\n",
        "        # Reshape la sortie pour qu'elle corresponde aux dimensions nécessaires pour la convolution\n",
        "        out = out.view(out.size(0), 256, self.init_size, self.init_size)  # Reshape pour passer à la couche suivante\n",
        "        img = self.conv_blocks(out)  # Passage dans les convolutions pour générer l'image\n",
        "\n",
        "        return img\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "i4-tmeP9v-_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "zN2U6PhzB3rA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, num_classes, img_size, channels):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.img_size = img_size\n",
        "        self.channels = channels\n",
        "\n",
        "        # Embedding des labels\n",
        "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
        "\n",
        "        # Définition du réseau\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(channels + num_classes, 64, 3, stride=2, padding=1),  # Concaténation sur les canaux\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(128, 256, 3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(256, 512, 3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(512, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512 * (img_size // 16) * (img_size // 16), 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img, labels):\n",
        "        # Convertir les labels en embeddings\n",
        "        label_embeds = torch.matmul(labels.float(), self.label_emb.weight)  # Matmul des labels avec les poids de l'embedding\n",
        "        print(\"Label embeds shape: \", label_embeds.shape)\n",
        "\n",
        "        # Étendre les embeddings des labels pour correspondre aux dimensions de l'image\n",
        "        label_embeds = label_embeds.view(label_embeds.size(0), -1, 1, 1)  # (batch_size, num_classes, 1, 1)\n",
        "        label_embeds = label_embeds.expand(-1, -1, img.size(2), img.size(3))  # (batch_size, num_classes, H, W)\n",
        "\n",
        "        # Concaténer les labels et l'image\n",
        "        d_in = torch.cat((img, label_embeds), 1)  # Concaténation sur la dimension des canaux (channels)\n",
        "\n",
        "        # Passer à travers le modèle pour obtenir la validité\n",
        "        print(d_in.shape)\n",
        "        validity = self.model(d_in)\n",
        "\n",
        "        return validity\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "YoHeDiHXJ-vX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialisation des modèles\n",
        "generator = Generator(latent_dim, num_classes, img_size, channels).to(device)\n",
        "discriminator = Discriminator(num_classes, img_size, channels).to(device)\n",
        "\n",
        "# Optimiseurs\n",
        "lr = 0.0002  # Learning rate\n",
        "optimizer_g = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))  # Adam pour le générateur\n",
        "optimizer_d = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))  # Adam pour le discriminateur\n",
        "\n",
        "# Fonction de perte\n",
        "adversarial_loss = nn.BCELoss()  # Binary Cross-Entropy Loss\n"
      ],
      "metadata": {
        "id": "8peJfSGXwtOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Boucle d'entraînement\n",
        "epochs = 50  # Nombre d'époques\n",
        "for epoch in range(epochs):\n",
        "    for i, (imgs, labels) in enumerate(train_loader):\n",
        "\n",
        "        batch_size = imgs.size(0)\n",
        "        imgs = imgs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Créer les labels réels et faux pour la fonction de perte\n",
        "        valid = torch.ones(batch_size, 1).to(device)\n",
        "        fake = torch.zeros(batch_size, 1).to(device)\n",
        "\n",
        "        # ----------- Entraîner le générateur -----------\n",
        "        optimizer_g.zero_grad()\n",
        "\n",
        "        # Générer un vecteur latent de bruit et le concaténer avec les labels\n",
        "        z = torch.randn(batch_size, latent_dim).to(device)\n",
        "\n",
        "        gen_imgs = generator(z, labels)\n",
        "        print(gen_imgs.shape)\n",
        "\n",
        "        # Calculer la perte du générateur\n",
        "        g_loss = adversarial_loss(discriminator(gen_imgs, labels), valid)\n",
        "        g_loss.backward()\n",
        "        optimizer_g.step()\n",
        "\n",
        "        # ----------- Entraîner le discriminateur -----------\n",
        "        optimizer_d.zero_grad()\n",
        "\n",
        "        # Calculer la perte pour les images réelles\n",
        "        real_loss = adversarial_loss(discriminator(imgs, labels), valid)\n",
        "\n",
        "        # Calculer la perte pour les images générées\n",
        "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach(), labels), fake)\n",
        "\n",
        "        # Total loss du discriminateur\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "        d_loss.backward()\n",
        "        optimizer_d.step()\n",
        "\n",
        "        # Affichage des pertes\n",
        "        if i % 50 == 0:\n",
        "            print(f\"[Epoch {epoch}/{epochs}] [Batch {i}/{len(train_loader)}] [D loss: {d_loss.item()}] [G loss: {g_loss.item()}]\")\n",
        "\n",
        "    # Sauvegarde des images générées à chaque époque pour visualisation\n",
        "    if epoch % 10 == 0:\n",
        "        with torch.no_grad():\n",
        "            z = torch.randn(25, latent_dim).to(device)\n",
        "            labels = torch.randint(0, num_classes, (25,)).to(device)\n",
        "            gen_imgs = generator(z, labels)\n",
        "            gen_imgs = gen_imgs.cpu().detach().numpy()\n",
        "\n",
        "            # Visualisation des images générées\n",
        "            fig, axes = plt.subplots(5, 5, figsize=(10, 10))\n",
        "            for ax, img in zip(axes.flatten(), gen_imgs):\n",
        "                ax.axis('off')\n",
        "                ax.imshow(np.transpose(img, (1, 2, 0)) * 0.5 + 0.5)  # Dé-normalisation\n",
        "            plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "kUXwEr6RwymR",
        "outputId": "058bc419-38af-4cff-88dd-088542a3a60d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 128, 128])\n",
            "Label embeds shape:  torch.Size([4, 40])\n",
            "torch.Size([4, 43, 128, 128])\n",
            "Label embeds shape:  torch.Size([4, 40])\n",
            "torch.Size([4, 43, 128, 128])\n",
            "Label embeds shape:  torch.Size([4, 40])\n",
            "torch.Size([4, 43, 128, 128])\n",
            "[Epoch 0/50] [Batch 0/40693] [D loss: 0.6934458017349243] [G loss: 0.6922383308410645]\n",
            "torch.Size([4, 3, 128, 128])\n",
            "Label embeds shape:  torch.Size([4, 40])\n",
            "torch.Size([4, 43, 128, 128])\n",
            "Label embeds shape:  torch.Size([4, 40])\n",
            "torch.Size([4, 43, 128, 128])\n",
            "Label embeds shape:  torch.Size([4, 40])\n",
            "torch.Size([4, 43, 128, 128])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-ecefbabf1a73>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# Total loss du discriminateur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreal_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfake_loss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0moptimizer_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3MD8tVWOz7Mw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}